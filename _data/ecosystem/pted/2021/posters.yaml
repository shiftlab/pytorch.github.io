- authors:
  - Brian Hu
  - Paul Tunison
  - Elim Schenck
  - Roddy Collins
  - Anthony Hoogs
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "Despite significant progress in the past few years, machine learning-based systems are still often viewed as “black boxes,” which lack the ability to explain their output decisions to human users. Explainable artificial intelligence (XAI) attempts to help end-users understand and appropriately trust machine learning-based systems. One commonly used technique involves saliency maps, which are a form of visual explanation that reveals what an algorithm pays attention to during its decision process. We introduce the xaitk-saliency python package, an open-source, explainable AI framework and toolkit for visual saliency algorithm interfaces and implementations, built for analytics and autonomy applications. The framework is modular and easily extendable, with support for several image understanding tasks, including image classification, image similarity, and object detection. We have also recently added support for the autonomy domain, by creating saliency maps for pixel-based deep reinforcement-learning agents in environments such as ATARI. Several example notebooks are included that demo the current capabilities of the toolkit. xaitk-saliency will be of broad interest to anyone who wants to deploy AI capabilities in operational settings and needs to validate, characterize and trust AI performance across a wide range of real-world conditions and application areas using saliency maps. To learn more, please visit: https://github.com/XAITK/xaitk-saliency."
  link: https://github.com/XAITK/xaitk-saliency
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F8.png 
  section: F8
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F8-thumb.png  
  title: "xaitk-saliency: Saliency built for analytics and autonomy applications"
# - authors:
#   - Ali Hatamizadeh
#   - Yucheng Tang
#   - Vishwesh Nath
#   - Dong Yang
#   - Holger Roth
#   - Bennett Landman
#   - Daguang Xu
#   categories:
#   - MEDICAL & HEALTHCARE, RESPONSIBLE AI
#   description: "A novel transformer-based architecture, dubbed UNETR, for semantic segmentation of volumetric medical images by reformulating this task as a 1D sequence-to-sequence prediction problem. Using a transformer encoder increases the model's ability to learn long-range dependencies and effectively captures global contextual representation at multiple scales. The effectiveness of UNETR has been validated on different volumetric segmentation tasks in CT and MRI modalities. UNETR achieves new state-of-the-art performance in both Standard and Free Competitions on the BTCV leaderboard for the multi-organ segmentation and outperforms competing approaches for brain tumor and spleen segmentation on the MSD dataset. UNETR has shown the potential to effectively learn the critical anatomical relationships represented in medical images"
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F7.png 
#   section: F7
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F7-thumb.png  
#   title: "UNETR: Transformers for 3D Medical Image Segmentation"
- authors:
  - Laila Rasmy
  - Ziqian Xie
  - Bingyu Mao
  - Khush Patel
  - Wanheng Zhang
  - Degui Zhi
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "CovRNN is a collection of recurrent neural network (RNN)-based models to predict COVID-19 patients' outcomes, using their available electronic health record (EHR) data on admission, without the need for specific feature selection or missing data imputation. CovRNN is designed to predict three outcomes: in-hospital mortality, need for mechanical ventilation, and long length of stay (LOS >7 days). Predictions are made for time-to-event risk scores (survival prediction) and all-time risk scores (binary prediction). Our models were trained and validated using heterogeneous and de-identified data of 247,960 COVID-19 patients from 87 healthcare systems, derived from the Cerner® Real-World Dataset (CRWD) and 36,140 de-identified patients' data derived from the Optum® de-identified COVID-19 Electronic Health Record v. 1015 dataset (2007 - 2020). CovRNN shows higher performance than do traditional models. It achieved an area under the receiving operating characteristic (AUROC) of 93% for mortality and mechanical ventilation predictions on the CRWD test set (vs. 91·5% and 90% for light gradient boost machine (LGBM) and logistic regression (LR), respectively) and 86.5% for prediction of LOS > 7 days (vs. 81·7% and 80% for LGBM and LR, respectively). For survival prediction, CovRNN achieved a C-index of 86% for mortality and 92·6% for mechanical ventilation. External validation confirmed AUROCs in similar ranges. https://www.medrxiv.org/content/10.1101/2021.09.27.2126"
  link: https://github.com/ZhiGroup/CovRNN
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F6.png 
  section: F6
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F6-thumb.png  
  title: "CovRNN—A collection of recurrent neural network models for predicting outcomes of COVID-19 patients using their EHR data"
- authors:
  - Sanzhar Askaruly
  - Nurbolat Aimakov
  - Alisher Iskakov
  - Hyewon Cho
  - Yujin Ahn
  - Myeong Hoon Choi
  - Hyunmo Yang
  - Woonggyu Jung
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "Deep learning has transformed many aspects of industrial pipelines recently. Scientists involved in biomedical imaging research are also benefiting from the power of AI to tackle complex challenges. Although the academic community has widely accepted image processing tools, such as scikit-image, ImageJ, there is still a need for a tool which integrates deep learning into biomedical image analysis. We propose a minimal, but convenient Python package based on PyTorch with common deep learning models, extended by flexible trainers and medical datasets. In this work, we also share theoretical dive in the form of course as well as minimal tutorials to run Android applications, containing models trained with Farabio."
  link: https://github.com/tuttelikz/farabio
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F5.png 
  section: F5
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F5-thumb.png  
  title: "Farabio - Deep learning for Biomedical Imaging"
- authors:
  - Fernando Pérez-García
  - Rachel Sparks
  - Sébastien Ourselin
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "Processing of medical images such as MRI or CT presents different challenges compared to RGB images typically used in computer vision: a lack of labels for large datasets, high computational costs, and the need of metadata to describe the physical properties of voxels. Data augmentation is used to artificially increase the size of the training datasets. Training with image patches decreases the need for computational power. Spatial metadata needs to be carefully taken into account in order to ensure a correct alignment and orientation of volumes. We present TorchIO, an open-source Python library to enable efficient loading, preprocessing, augmentation and patch-based sampling of medical images for deep learning. TorchIO follows the style of PyTorch and integrates standard medical image processing libraries to efficiently process images during training of neural networks. TorchIO transforms can be easily composed, reproduced, traced and extended. We provide multiple generic preprocessing and augmentation operations as well as simulation of MRI-specific artifacts.TorchIO was developed to help researchers standardize medical image processing pipelines and allow them to focus on the deep learning experiments. It encourages good open-science practices, as it supports experiment reproducibility and is version-controlled so that the software can be cited precisely. Due to its modularity, the library is compatible with other frameworks for deep learning with medical images."
  link: https://github.com/fepegar/torchio/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F4.png 
  section: F4
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F4-thumb.png  
  title: "TorchIO: Pre-processing & Augmentation of Medical Images for Deep Learning Applications"
- authors:
  - Michael Zephyr
  - Prerna Dogra
  - Richard Brown
  - Wenqi Li
  - Eric Kerfoot
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "Healthcare image analysis for both radiology and pathology is increasingly being addressed with deep-learning-based solutions. These applications have specific requirements to support various imaging modalities like MR, CT, ultrasound, digital pathology, etc. It is a substantial effort for researchers in the field to develop custom functionalities to handle these requirements. Consequently, there has been duplication of effort, and as a result, researchers have incompatible tools, which makes it hard to collaborate. MONAI stands for Medical Open Network for AI. Its mission is to accelerate the development of healthcare imaging solutions by providing domain-specialized building blocks and a common foundation for the community to converge in a native PyTorch paradigm."
  link: https://monai.io/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F3.png 
  section: F3
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F3-thumb.png  
  title: "MONAI: A Domain Specialized Library for Healthcare Imaging"
- authors:
  - Sahar Karimi
  - Beliz Gokkaya
  - Audrey Flower
  - Ehsan Emamjomeh-Zadeh
  - Adly Templeton
  - Ilknur Kaynar Kabul
  - Erik Meijer
  categories:
  - MEDICAL & HEALTHCARE, RESPONSIBLE AI
  description: "We are presenting a framework for building Bayesian Neural Networks (BNN). One of the critical use cases of BNNs is uncertainty quantification of ML predictions in deep learning models. Uncertainty quantification leads to more robust and reliable ML systems that are often employed to prevent catastrophic outcomes of overconfident predictions especially in sensitive applications such as integrity, medical imaging and treatments, self driving cars, etc.. Our framework provides tools to build BNN models, estimate the uncertainty of their predictions, and transform existing models into their BNN counterparts. We discuss the building blocks and API of our framework along with a few examples and future directions."
  link:
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F2.png 
  section: F2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F2-thumb.png  
  title: "A Framework for Bayesian Neural Networks"
# - authors:
#   - Pranav Bhamidipati
#   - Guruprasad Raghavan
#   - Matt Thomson
#   categories:
#   - MEDICAL & HEALTHCARE, RESPONSIBLE AI
#   description: "Biological tissues reliably grow into precise, functional structures from simple starting states during development. Throughout the developmental process, the energy of a tissue changes depending on its natural resistance to deformations such as stretching, bending, shearing, and torsion. In this paper, we represent tissue structures as shapes and develop a mathematical framework using PyTorch's autograd functionality and TorchVision to discover paths on the tissue shape manifold to minimize the total energy during development. We find that paths discovered by gradient descent and the geodesic algorithm outperform naive shape interpolation in energetic terms and resemble strategies observed in development. Broadly, these tools built on PyTorch frameworks can be used to understand and compare shape transformations in biology and propose optimal strategies for synthetic tissue engineering."
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F1.png 
#   section: F1
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/F1-thumb.png  
#   title: "Traversing Geodesics to Grow Biological Structures"
# - authors:
#   - Zhengyang Feng
#   - Shaohua Guo
#   categories:
#   - AUDIO, IMAGE & VIDEO, VISION
#   description: "PytorchAutoDrive is an open-source codebase to facilitate autonomous driving research, which focuses on autonomous driving perception tasks. Based on PyTorch and TorchVision, it provides a unified level of tricks for fair evaluation of different methods, beginner-friendly codes, visualization tools, and benchmarking of model speed/flops count. Currently, with PyTorch DDP and AMP, fast training of semantic segmentation and lane detection tasks are supported on 7 datasets, with 9 re-implemented methods. With help from the PyTorch developer community, we will support more methods and functionals in the future https://github.com/voldemortX/pytorch-auto-drive"
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E10.png 
#   section: E10
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E10-thumb.png  
#   title: "PytorchAutoDrive: Toolkit & Fair Benchmark for Autonomous Driving Research"
- authors:
  - Philip Meier
  - torchvision team
  - torchdata team
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "torchvision provides a lot of image and video datasets as well as transformations for research and prototyping. In fact, the very first release of torchvision in 2016 was all about these two submodules. Since their inception their extent has grown organically and became hard to maintain and sometimes also hard to use. Over the years we have gathered a lot of user feedback and decided to revamp the datasets and transforms. This poster will showcase the current state of the rework and compare it to the hopefully soon to be legacy API."
  link:  https://pytorchvideo.org/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E9-thumb.png 
  section: E9
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E9-thumb.png  
  title: "Revamp of torchvision datasets and transforms"
- authors:
  - Wenwei Zhang
  - Han Lyu
  - Kai Chen
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "OpenMMLab builds open-source tool boxes for computer vision. It aims to 1) provide high-quality codebases to reduce the difficulties in algorithm reimplementation; 2) create efficient deployment toolchains targeting a variety of inference engines and devices; 3) build a solid foundation for the community to bridge the gap between academic research and industrial applications. Based on PyTorch, OpenMMLab develops MMCV to provide unified abstract interfaces and common utils, which serve as a foundation of the whole system. Since the initial release in October 2018, OpenMMLab has released 15+ tool boxes covering different research areas. It has implemented 200+ algorithms and released contain 1800+ pre-trained models. With tighter collaboration with the community, OpenMMLab will open source more toolboxes and full-stack toolchains in the future."
  link: openmmlab.com
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E8.png 
  section: E8
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E8-thumb.png  
  title: "OpenMMLab: Open-Source Toolboxes for Artificial Intelligence"
# - authors:
#   - Ayse Ayyuce Demirbas
#   categories:
#   - AUDIO, IMAGE & VIDEO, VISION
#   description: "A Generative Adversarial Network (GAN) is a powerful architecture to generate realistic images. In this work, we generate new lung adenocarcinoma tissue images with GAN using Lung and Colon Cancer Histopathological Images dataset. Additionally, we propose two convolutional neural network models for the generator and discriminator."
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E7.png 
#   section: E7
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E7-thumb.png  
#   title: "Generation of Synthetic Lung Cancer Histopathological Images using Generative Adversarial Networks"
# - authors:
#   - Haoqi Fan*
#   - Tullie Murrell*
#   - Heng Wang†
#   - Kalyan Vasudev Alwala†
#   - Yanghao Li†
#   - Yilei Li†
#   - Bo Xiong†
#   - Nikhila Ravi
#   - Meng Li
#   - Haichuan Yang
#   - Jitendra Malik
#   - Ross Girshick
#   - Matt Feiszli
#   - Aaron Adcock‡
#   - Wan-Yen Lo‡
#   - Christoph Feichtenhofer‡
#   categories:
#   - AUDIO, IMAGE & VIDEO, VISION
#   description: "We introduce PyTorchVideo, an open-source deep-learning library that provides a rich set of modular, efficient, and reproducible components for a variety of video understanding tasks, including classification, detection, self-supervised learning, and low-level processing. The library covers a full stack of video understanding tools including multimodal data loading, transformations, and models that reproduce state-of-the-art performance. PyTorchVideo further supports hardware acceleration that enables real-time inference on mobile devices. The library is based on PyTorch and can be used by any training framework; for example, PyTorchLightning, PySlowFast, or Classy Vision. PyTorchVideo is available at https://pytorchvideo.org/."
#   link: https://pytorchvideo.org/
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E6.png 
#   section: E6
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E6-thumb.png  
#   title: "PyTorchVideo - A Deep Learning Library for Video Understanding"
- authors:
  - Siddha Ganju
  - Sayak Paul
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "Floods wreak havoc throughout the world, causing billions of dollars in damages, and uprooting communities, ecosystems and economies. Aligning flood extent mapping with local topography can provide a plan-of-action that the disaster response team can consider. Thus, remote flood level estimation via satellites like Sentinel-1 can prove to be remedial. The Emerging Techniques in Computational Intelligence (ETCI) competition on Flood Detection tasked participants with predicting flooded pixels after training with synthetic aperture radar (SAR) images in a supervised setting. We use a cyclical approach involving two stages (1) training an ensemble model of multiple UNet architectures with available high and low confidence labeled data and, generating pseudo labels or low confidence labels on the entire unlabeled test dataset, and then, (2) filter out quality generated labels and, (3) combining the generated labels with the previously available high confidence labeled dataset. This assimilated dataset is used for the next round of training ensemble models. This cyclical process is repeated until the performance improvement plateaus. Additionally, we post-process our results with Conditional Random Fields. Our approach sets the second-highest score on the public hold-out test leaderboard for the ETCI competition with 0.7654 IoU. To the best of our knowledge we believe this is one of the first works to try out semi-supervised learning to improve flood segmentation models."
  link: https://github.com/sidgan/ETCI-2021-Competition-on-FLood-Detection
  poster_link:  https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E5.png 
  section: E5
  thumbnail_link:  https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E5-thumb.png  
  title: "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning"
# - authors:
#   - Kevin Zakka
#   - Andy Zeng
#   - Pete Florence
#   - Jonathan Tompson
#   - Jeannette Bohg
#   - Debidatta Dwibedi
#   categories:
#   - AUDIO, IMAGE & VIDEO, VISION
#   description: "We investigate the visual cross-embodiment imitation setting, in which agents learn policies from videos of other agents (such as humans) demonstrating the same task, but with stark differences in their embodiments -- end-effector shape, actions, etc. In this work, we demonstrate that it is possible to automatically discover and learn vision-based reward functions from cross-embodiment demonstration videos that are robust to these differences. Specifically, we present a self-supervised method for Cross-embodiment Inverse Reinforcement Learning (XIRL) that leverages temporal cycle-consistency constraints to learn deep visual embeddings that capture task progression from offline videos of demonstrations across multiple expert agents, each performing the same task differently due to embodiment differences. We show empirically that if the embeddings are aware of task progress, simply taking the negative distance between the current state and goal state in the learned embedding space is useful as a reward for training policies with reinforcement learning. We find our learned reward function not only works for embodiments seen during training, but also generalizes to entirely new embodiments. Additionally, when transferring real-world human demonstrations to a simulated robot, we find that XIRL is more sample efficient than current best methods."
#   link: https://x-irl.github.io/
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E4.png 
#   section: E4
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E4-thumb.png  
#   title: "XIRL: Cross-embodiment Inverse Reinforcement Learning"
- authors:
  - Xiaoyu Liu
  - James Wagner
  - Roy Fejgin
  - Joan Serra
  - Santiago Pascual
  - Cong Zhou
  - Jordi Pons
  - Vivek Kumar
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "Speech enhancement is a fundamental audio processing task that has experienced a radical change with the advent of deep learning technologies. We will overview the main characteristics of the task and the key principles of existing deep learning solutions. We will be presenting the past and present work done by our group with the overall goal of delivering the best possible intelligibility and sound quality. Finally, we will provide our view on the future of speech enhancement and show how our current long-term research aligns with such a view."
  link:
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E3.png 
  section: E3
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E3-thumb.png  
  title: "Real time Speech Enhancement"
- authors:
  - Edgar Riba
  - Dmytro Mishkin
  - Jian Shi
  - Luis Ferraz
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "Kornia is a differentiable library that allows classical computer vision to be integrated into deep learning models. It consists of a set of routines and differentiable modules to solve generic computer vision problems. At its core, the package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions."
  link: https://kornia.github.io//
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E2.png 
  section: E2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E2-thumb.png  
  title: "Kornia AI: Low Level Computer Vision for AI"
- authors:
  - Daniel Neimark
  - Omri Bar
  - Maya Zohar
  - Dotan Asselmann
  categories:
  - AUDIO, IMAGE & VIDEO, VISION
  description: "This paper presents VTN, a transformer-based framework for video recognition. Inspired by recent developments in vision transformers, we ditch the standard approach in video action recognition that relies on 3D ConvNets and introduce a method that classifies actions by attending to the entire video sequence information. Our approach is generic and builds on top of any given 2D spatial network. In terms of wall runtime, it trains 16.1× faster and runs 5.1× faster during inference while maintaining competitive accuracy compared to other state-of-the-art methods. It enables whole video analysis, via a single end-to-end pass, while requiring 1.5× fewer GFLOPs. We report competitive results on Kinetics-400 and present an ablation study of VTN properties and the trade-off between accuracy and inference speed. We hope our approach will serve as a new baseline and start a fresh line of research in the video recognition domain. Code and models are available at: https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md . See paper: https://arxiv.org/abs/2102.00719"
  link: https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E1.png 
  section: E1
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/E1-thumb.png  
  title: "Video Transformer Network"
- authors:
  - Dr. Ehsan Saboori
  - Dr. Sudhakar Sah
  - MohammadHossein AskariHemmat Saad Ashfaq
  - Alex Hoffman
  - Olivier Mastropietro
  - Davis Sawyer
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "The emergence of Deep Neural Networks (DNNs) on embedded and low-end devices holds tremendous potential to expand the adoption of AI technologies to wider audiences. However, making DNNs applicable for inference on such devices using techniques such as quantization and model compression, while maintaining model accuracy, remains a challenge for production deployment. Furthermore, there is a lack of inference engines available in any AI framework to run such low precision networks. Our work presents a novel inference engine and model compression framework that automatically enables PyTorch developers to quantize and run their deep learning models at 2bit and 1bit precision, making them faster, smaller and more energy-efficient in production. DLRT empowers PyTorch developers to unlock advanced AI on low-power CPUs, starting with ARM CPUs and MCUs. This work allows AI researchers and practitioners to achieve 10x faster inference and near-GPU level performance on a fraction of the power and cost."
  link: https://github.com/deeplite
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D7.png 
  section: D7
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D7-thumb.png  
  title: "DLRT: Ultra Low-Bit Precision Inference Engine for PyTorch on CPU"
- authors:
  - Adway Dhillo
  - Nidhin Pattaniyil
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "This poster is for a data scientist or ML engineer looking to productionalize their pytorch models. It will cover post training steps that should be taken to optimize the model such as quantization and torch script. It will also walk the user in packaging and serving the model through Facebook’s TorchServe. Will also cover benefits of script mode and Pytorch JIT. Benefits of Torch Serve: high performance serving , multi model serving , model version for A/B testing, server side batching, support for pre and post processing"
  link: https://pytorch.org/serve/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D6.png  
  section: D6
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D6-thumb.png   
  title: "Serving PyTorch Models in Production at Walmart Search"
- authors:
  - Shengyi Huang
  - Rousslan Fernand Julien Dossa
  - Chang Ye
  - Jeff Braga
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "CleanRL is an open-source library that provides high-quality single-file implementations of Deep Reinforcement Learning algorithms. It provides a simpler yet scalable developing experience by having a straightforward codebase and integrating production tools to help interact and scale experiments. In CleanRL, we put all details of an algorithm into a single file, making these performance-relevant details easier to recognize. Additionally, an experiment tracking feature is available to help log metrics, hyperparameters, videos of an agent's gameplay, dependencies, and more to the cloud. Despite succinct implementations, we have also designed tools to help scale, at one point orchestrating experiments on more than 2000 machines simultaneously via Docker and cloud providers.environments. The source code can be found at https://github.com/vwxyzjn/cleanrl."
  link: https://github.com/vwxyzjn/cleanrl/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D5.png 
  section: D5
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D5-thumb.png  
  title: "CleanRL: high-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features"
- authors:
  - Nidhin Pattaniyil
  - Reshama Shaikh
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "As technology improves, so does the use of training deep learning models. Additionally, since the time spent on mobile devices is greater than on desktop, the demand for applications running natively on mobile devices is also high. This demo will go through a complete example of training a deep learning vision classifier on the Food-101 dataset using PyTorch. We then deploy it on web and mobile using TorchServe and PyTorch Mobile."
  link: https://github.com/npatta01/pytorch-food
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D4.png 
  section: D4
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D4-thumb.png  
  title: "Deploying a Food Classifier on PyTorch Mobile"
# - authors:
#   - James McCaffrey
#   - Ricky Loynd
#   - Amanda Minnich
#   - Bryan Xia
#   categories:
#   - PERFORMANCE, PRODUCTION & DEPLOYMENT
#   description: "Anomaly detection using deep neural autoencoder reconstruction error is a well-known and effective technique. Reconstruction error anomaly detection compares X and reconstructed X, and when they differ greatly, X is likely anomalous in some way. Recent research has explored an evolution of the autoencoder reconstruction error technique, called variational autoencoder (VAE) reconstruction probability. Briefly, a source data item X generates an internal (u1, v1) mean and standard deviation (equivalently, variance or log-variance) which define a probability distribution P. The P(u1, v1) distribution determines a Q(u2, v2) distribution which is sampled to generate a reconstructed X. The VAE reconstruction probability technique determines how likely it is that the source item X came from the Q(u2, v2) distribution, and if the likelihood is small, X is tagged as anomalous. Experiments on synthetic datasets suggest that the autoencoder reconstruction error and VAE reconstruction probability techniques identify different types of anomalous data items."
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D3.png 
#   section: D3
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D3-thumb.png  
#   title: "Variational Autoencoder Reconstruction Probability Anomaly Detection"
- authors:
  - Naren Dasan
  - Nick Comly
  - Dheeraj Peri
  - Anurag Dixit
  - Abhiram Iyer
  - Bo Wang
  - Arvind Sridhar
  - Boris Fomitchev
  - Josh Park
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "Learn how to accelerate PyTorch inference, from framework, for model deployment. The PyTorch integration for TensorRT makes the performance of TensorRT's GPU optimizations available in PyTorch for any model. We will walk you through how with 3 lines of code you can go from a trained model to optimized TensorRT-embedded TorchScript, ready to deploy to a production environment."
  link: https://github.com/NVIDIA/Torch-TensorRT/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D2.png 
  section: D2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D2-thumb.png  
  title: "Torch-TensorRT: Accelerating Inference Performance Directly from PyTorch using TensorRT"
- authors:
  - Jean Kossaifi
  categories:
  - PERFORMANCE, PRODUCTION & DEPLOYMENT
  description: "Most of the data in modern machine learning (e.g. fMRI, videos, etc) is inherently multi-dimensional and leveraging that structure is crucial for good performance. Tensor methods are the natural way to achieve this and can improve deep learning and enable i) large compression ratios through a reduction of the number of parameters, ii) computational speedups, iii) improved performance and iv) better robustness. The TensorLy project provides the tools to manipulate tensors, including tensor algebra, regression and decomposition. TensorLy-Torch builds on top of this and enables tensor-based deep learning by providing out-of-the-box tensor based PyTorch layers that can be readily combined with any deep neural network architecture and takes care of things such as initialization and tensor dropout."
  link: http://tensorly.org/quantum
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D1.png 
  section: D1
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/D1-thumb.png  
  title: "Tensorized Deep Learning with TensorLy-Torch"
- authors:
  - Sergey Kolesnikov
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Catalyst is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop."
  link: https://catalyst-team.com/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C12.png 
  section: C12
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C12-thumb.png  
  title: "Catalyst-Accelerated Deep Learning R&D"
- authors:
  - Amog Kamsetty
  - Richard Liaw
  - Will Drevo
  - Michael Galarnyk
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "PyTorch Lightning is a library that provides a high-level interface for PyTorch which helps you organize your code and reduce boilerplate. By abstracting away engineering code, it makes deep learning experiments easier to reproduce and improves developer productivity. PyTorch Lightning also includes plugins to easily parallelize your training across multiple GPUs. This parallel training, however, depends on a critical assumption: that you already have your GPU(s) set up and networked together in an efficient way for training. While you may have a managed cluster like SLURM for multi-node training on the cloud, setting up the cluster and its configuration is no easy task. Ray Lightning was created with this problem in mind to make it easy to leverage multi-node training without needing extensive infrastructure expertise. It is a simple and free plugin for PyTorch Lightning with a number of benefits like simple setup, easy scale up, seamless creation of multi-node clusters on AWS/Azure/GCP via the Ray Cluster Launcher, and an integration with Ray Tune for large-scale distributed hyperparameter search and state of the art algorithms"
  link: https://github.com/ray-project/ray_lightning
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C11.png 
  section: C11
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C11-thumb.png  
  title: "Ray Lightning: Easy Multi-node PyTorch Lightning training"
- authors:
  - Jin Howe Teo
  - Way Yen Chen
  - Najib Ninaba
  - Choo Heng Chong Mark
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Data sits as the centerpiece of any machine learning endeavour, yet in many real-world projects, a single party’s data is often insufficient and needs to be augmented with data from other sources. This is unfortunately easier said than done, as there are many innate concerns (be it regulatory, ethical, commercial etc.) stopping parties from exchanging data. Fortunately, there exists an emerging privacy-preserving machine learning technology called Federated Learning. It enables multiple parties holding local data to collaboratively train machine learning models without actually exchanging their data with one another, hence preserving the confidentiality of different parties’ local data.Today, we will be showcasing Synergos, a distributed platform built here at AI Singapore to facilitate the adoption of Federated Learning. Specifically, it strives to make the complex mechanisms involved in any federated endeavour simple, accessible and sustainable."
  link: https://github.com/aimakerspace/synergos_simulator
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C10.png 
  section: C10
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C10-thumb.png  
  title: "Supercharge your Federated Learning with Synergos"
- authors:
  - Aurick Qiao
  - Omkar Pangarkar
  - Richard Fan
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "AdaptDL is an open source framework and scheduling algorithm that directly optimizes cluster-wide training performance and resource utilization. By elastically re-scaling jobs, co-adapting batch sizes and learning rates, and avoiding network interference, AdaptDL improves shared-cluster training compared with alternative schedulers. AdaptDL can automatically determine the optimal number of resources given a job’s need. It will efficiently add or remove resources dynamically to ensure the highest-level performance. The AdaptDL scheduler will automatically figure out the most efficient number of GPUs to allocate to your job, based on its scalability. When the cluster load is low, your job can dynamically expand to take advantage of more GPUs. AdaptDL offers an easy-to-use API to make existing PyTorch training code elastic with adaptive batch sizes and learning rates. We have also ported AdaptDL to Ray/Tune which can automatically scale trials of an Experiment and can be used to schedule stand-alone PyTorch training jobs on the cloud in a cost-effective way."
  link: https://github.com/petuum/adaptdl
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C9.png 
  section: C9
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C9-thumb.png  
  title: "AdaptDL: An Open-Source Resource-Adaptive Deep Learning Training and Scheduling Framework"
- authors:
  - Vasiliy Kuznetsov
  - James Reed
  - Jerry Zhang
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Describes a prototype PyTorch workflow to perform quantization syntax transforms in Eager mode with: * no model changes needed (compared to Eager mode which requires manual quant/dequant insertion and fusion) * almost no model syntax restrictions (compared to FX graph mode which requires symbolic traceability)"
  link: https://pytorch.org/docs/stable/quantization.html
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C8.png  
  section: C8
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C8-thumb.png   
  title: "Define-by-run quantization"
- authors:
  - Charles Hernandez
  - Vasiliy Kuznetzov
  - Haixin Liu
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "wrong when it doesn't satisfy the accuracy we expect. Debugging the accuracy issue of quantization is not easy and time consuming. The Fx Numeric Suite Core APIs allows users to better diagnose the source of their quantization error for both statically and dynamically quantized modelsThis poster gives an overview of the core APIs and techniques available to users through the Fx Numeric Suite, and how they can use them to improve quantization performance."
  link:
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C7.png 
  section: C7
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C7-thumb.png  
  title: "Fx Numeric Suite Core APIs"
- authors:
  - J.K. Eshraghian
  - M. Ward
  - E.O. Neftci
  - G. Lenz
  - X. Wang
  - G. Dwivedi
  - M. Bennamoun
  - D.S. Jeong
  - W.D. Lu
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "The brain is the perfect place to look for inspiration to develop more efficient neural networks. One of the main differences with modern deep learning is that the brain encodes and processes information as spikes rather than continuous activations. Combining the training methods intended for neural networks with the sparse, spiking activity inspired by biological neurons has shown the potential to improve the power efficiency of training and inference by several orders of magnitude. snnTorch is a Python package for performing gradient-based learning with spiking neural networks. It extends the capabilities of PyTorch, taking advantage of its GPU accelerated tensor computation and applying it to networks of event-driven spiking neurons.  snnTorch is designed to be intuitively used with PyTorch, as though each spiking neuron were simply another activation in a sequence of layers. It is therefore agnostic to fully-connected layers, convolutional layers, residual connections, etc. The classical challenges that have faced the neuromorphic engineering community, such as the non-differentiability of spikes, the dead neuron problem, vanishing gradients in backpropagation-through-time, are effectively solved in snnTorch and enable the user to focus on building applications that leverage sparsity and event-driven data streams."
  link: https://snntorch.readthedocs.io/en/latest/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C6.png 
  section: C6
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C6-thumb.png  
  title: "snnTorch: Training spiking neural networks using gradient-based optimization"
- authors:
  - Daniel Falbel
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Last year the PyTorch for the R language project has been released allowing R users to benefit of PyTorch's speed and flexibility. Since then we have a growing community of contributors that are both improving the torch for R interface, building research and products on top of it and using it to teach deep learning methods. In this poster we will showcase what are the past and current developments in the PyTorch for R project as well as what are our plans for the future."
  link: https://torch.mlverse.org/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C5.png 
  section: C5
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C5-thumb.png  
  title: "PyTorch for R"
- authors:
  - Laurent Mazare
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "The main front-end for using PyTorch is its Python API, however LibTorch provides a lower level C++ API to manipulate tensors, perform automatic differentiation, etc. ocaml-torch and tch-rs are two open-source projects providing wrappers for this C++ API respectively in OCaml and Rust. Users can then write OCaml and Rust code to create new models, perform inference and training, and benefit from the guarantees provided by strongly typed programming languages and functional programming. They can also use TorchScript to leverage existing Python models. The libraries provide various examples, ranging from the main computer vision models to a minimalist GPT implementation.
  The main challenges for these bindings are to provide idiomatic APIs adapted to the languages specificities; to automatically generate most of the bindings code as there are thousands of C++ functions to expose; and to interact properly with the memory models for each language."
  link: https://github.com/laurentMazare/ocaml-torch
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C4.png 
  section: C4
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C4-thumb.png  
  title: "ocaml-torch and tch-rs: writing and using PyTorch models using OCaml or Rust"
- authors:
  - Ari Bornstein
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Flash is a high-level deep learning framework for fast prototyping, baselining, finetuning and solving deep learning problems. It features a set of tasks for you to use for inference and finetuning out of the box, and an easy to implement API to customize every step of the process for full flexibility. Flash is built for beginners with a simple API that requires very little deep learning background, and for data scientists, Kagglers, applied ML practitioners and deep learning researchers that want a quick way to get a deep learning baseline with advanced features PyTorch Lightning offers. Flash enables you to easily configure and run complex AI recipes for over 15 tasks across 7 data domains"
  link: https://github.com/PyTorchLightning
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C3.png 
  section: C3
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C3-thumb.png  
  title: "PyTorch Lightning Flash - Your PyTorch AI Factory"
- authors:
  - Victor Fomin
  - Taras Savchyn
  - Priyansi
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "PyTorch-Ignite is a high-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently. PyTorch-Ignite is designed to be at the crossroads of high-level Plug & Play features and under-the-hood expansion possibilities. The tool aims to improve the deep learning community's technical skills by promoting best practices where things are not hidden behind a divine tool that does everything, but remain within the reach of users. PyTorch-Ignite differs from other similar tools by allowing users to compose their applications without being focused on a super multi-purpose object, but rather on weakly coupled components allowing advanced customization."
  link: https://pytorch-ignite.ai/ecosystem/ 
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C2.png  
  section: C2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C2-thumb.png   
  title: "PyTorch-Ignite: Training and evaluating neural networks flexibly and transparently"
- authors:
  - Albert Jimenez
  - Mohamed Akrout
  categories:
  - EXTENDING PYTORCH, APIs, PARALLEL & DISTRIBUTED TRAINING
  description: "Backpropagation is the default algorithm for training deep neural networks due to its simplicity, efficiency and high convergence rate. However, its requirements make it impossible to be implemented in a human brain. In recent years, more biologically plausible learning methods have been proposed. Some of these methods can match backpropagation accuracy, and simultaneously provide other extra benefits such as faster training on specialized hardware (e.g., ASICs) or higher robustness against adversarial attacks. While the interest in the field is growing, there is a necessity for open-source libraries and toolkits to foster research and benchmark algorithms. In this poster, we present BioTorch, a software framework to create, train, and benchmark biologically motivated neural networks. In addition, we investigate the performance of several feedback alignment methods proposed in the literature, thereby unveiling the importance of the forward and backward weight initialization and optimizer choice. Finally, we provide a novel robustness study of these methods against state-of-the-art white and black-box adversarial attacks."
  link: https://github.com/jsalbert/biotorch
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C1.png 
  section: C1
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/C1-thumb.png  
  title: "Benchmarking the Accuracy and Robustness of Feedback Alignment Methods"
- authors:
  - Ludovic Denoyer
  - Alfredo de la Fuente
  - Song Duong
  - Jean-Baptiste Gaya
  - Pierre-Alexandre Kamienny
  - Daniel H. Thompson
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: "salina is a lightweight library extending PyTorch modules for the development of sequential decision models. It can be used for Reinforcement Learning (including model-based with differentiable environments, multi-agent RL, ...), but also in a supervised/unsupervised learning settings (for instance for NLP, Computer Vision, etc..)."
  link: https://github.com/facebookresearch/salina
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B7.png 
  section: B7
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B7-thumb.png  
  title: "Salina: Easy programming of Sequential Decision Learning and Reinforcement Learning Models in pytorch"
- authors:
  - Zafar Takhirov
  - Karen Zhou
  - Raghuraman Krishnamoorthi
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: "Two new toolflows for model pruning are introduced: Sparsifier and Pruner, which enable unstructured and structured pruning of the model weights respectively. The toolflow can be combined with other optimization techniques, such as quantization to achieve even higher levels of model compression. In addition to that, the \"Pruner\" toolflow can also be used for \"shape propagation\", where the physical structure of the model is modified after structured pruning (in FX graph mode only).This poster gives a high-level overview of the prototype API, usage example, currently supported sparse quantized kernels, as well as provides a brief overview of future plans"
  link: https://github.com/pytorch/pytorch
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B6.png 
  section: B6
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B6-thumb.png  
  title: "Structured and Unstructured Pruning Workflow in PyTorch"
- authors:
  - François-Guillaume Fernandez
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: "One of the core inconveniences of Deep Learning comes from its interpretability, which remains obscure for most non-basic convolutional models. Their very      performances are granted by optimization processes that have high degrees of freedom and no constraints on explainability. Fortunately, modern frameworks mechanisms grant access to information flow in their components, which paved the way to building intuition around result interpretability in CNN models. The main contributions of the author are described as follows:
  - building a flexible framework for class activation computation
  - providing high-quality implementations of most popular methods
  - making these methods usable by entry users as well as researchers
  The open-source project is available here: https://github.com/frgfm/torch-cam"
  link: https://github.com/frgfm/torch-cam
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B5.png 
  section: B5
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B5-thumb.png  
  title: "Torch-CAM: class activation explorer"
- authors:
  - Nikolaos Zioulis
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: moai is a PyTorch-based AI Model Development Kit (MDK) that seeks to improve data-driven model workflows, design and understanding. It relies on hydra for handling configuration and lightning for handling infrastructure. As a kit, It offers a set of actions to `train` or `evaluate` models using the corresponding actions which consume configuration files.  Apart from the definition of the model, data, training scheme, optimizer, visualization and logging, these configuration files additionally use named tensors to define tensor processing graphs. These are created by chaining various building blocks called monads, which are functional units or otherwise single responsibility modules. Monad parameters and input/output tensors are defined on the configuration file, allowing for the entire model to be summarized into a single file. This opens up novel functionalities like querying for inter-model differences using the `diff` action, or aggregating the results of multiple models using the `plot` action which uses hiplot to compare models in various ways. moai facilitates high quality reproduction (using the `reprod` action), as apart from automatically handling all boilerplate related to it, it standardizes the process of developing modules/monads and implicitly logs all hyperparameters. Even though no code is required, moai exploits python’s flexibility to allow developers to integrate their own code into its engine from external projects, vastly increasing their productivity.
  link: https://github.com/ai-in-motion/moai
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B4.png 
  section: B4
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B4-thumb.png  
  title: "moai: A Model Development Kit to Accelerate Data-driven Workflows"
- authors:
  - Vaibhav Singh
  - Rajesh Thallam
  - Jordan Totten
  - Karl Weinmeister
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: Machine Learning Operationalization has rapidly evolved in the last few years with a growing set of tools for each phase of development. From experimentation to automated model analysis and deployment, each of these tools offer some unique capabilities. In this work we survey a slice of these tools and demonstrate an opinionated example of an end to end CI/CD pipeline for PyTorch model development and deployment using Vertex AI SDK. The goal of this session is to aid an informed conversation on the choices available to PyTorch industry practitioners who are looking to operationalize their ML models, and to researchers who are simply trying to organize their experiments. Although our implementation example will make tool choices at various stages, we will be focused on ML design patterns that are applicable to a wide variety of commercial and open-source offerings.
  link: https://github.com/GoogleCloudPlatform/vertex-ai-samples
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B3.png 
  section: B3
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B3-thumb.png  
  title: "Building Production ML Pipelines for PyTorch Models"
- authors:
  - George Hosu
  - Particio Cerda-Mardini
  - Natasha Seelam
  - Jorge Torres
  categories:
  - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
  description: Nearly 64% of companies take over a month to a year to deploy a single machine learning (ML) model into production [1]. Many of these companies cite key challenges integrating with complex ML frameworks as a root cause [1], as there is still a gap between where data lives, how models are trained, and how downstream applications access predictions from models [1, 2].  MindsDB is a PyTorch-based ML platform that aims to solve fundamental MLOps challenges by abstracting ML models as “virtual tables”, allowing models to be queried in the same natural way users work with data in databases. As data is diverse and varied, we recently developed an open-source declarative syntax, named “JSON-AI” to allow others to customize ML model internals without changing source code.  We believe that the key elements of the data science (DS)/ML pipeline, namely data pre-processing/cleaning, feature engineering, and model-building [2], should be automated in a robust, reliable, and reproducible manner with simplicity. JSON-AI allows you refined control of each of these steps, and enables users to bring custom routines into their ML pipeline. In our poster, we will show how a user interfaces with JSON-AI to bring original approaches to each of the aforementioned parts of the DS/ML, along with control over analysis and explainability tools. [1] Algorithmia (2021). 2021 state of enterprise machine learning [2] “How Much Automation Does a Data Scientist Want?” ArXiV (2021)
  link: https://github.com/mindsdb/mindsdb/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B2.png 
  section: B2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B2-thumb.png  
  title: "Customizing MLOps pipelines with JSON-AI: a declarative syntax to streamline ML in the database"
# - authors:
#   - Moses Gurtmann
#   - Erez Schnaiderl
#   categories:
#   - ML Ops, MODELS, MODEL OPTIMIZATION & INTERPRETABILITY
#   description: "Both from sanity considerations and the productivity perspective, Data Scientists, ML engineers, Graduate students, and other research-facing roles are all starting to adopt best-practices from production-grade MLOps. However, most toolchains come with a hefty price of extra code and maintenance, which reduces the actual time available for R&D. We will show an alternative approach using ClearML, the open-source MLOps solution. In this “best-practices” poster, we will overview the “must-haves” of R&D-MLOPs: Orchestration, Automation, and Reproducibility. These enable easy remote execution through magically reproducible setups and even custom, reusable, bottom-up pipelines. We will take a single example and schematically transform it from the “as downloaded from GitHub” stage to a fully-fledged, scalable, version-controlled, parameterizable R&D pipeline. We will measure the number of changes needed to the codebase and provide evidence of real low-cost integration. All code, logs, and metrics will be available as supporting information"
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B1.png 
#   section: B1
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/B1-thumb.png  
#   title: "The Fundamentals of MLOps for R&D: Orchestration, Automation, Reproducibility"
- authors:
  - Robin Lobel
  categories:
  - ACCELERATORS, TOOLS, LIBRARY, DATA
  description: TorchStudio is an open-source, full-featured IDE for PyTorch. It aims to simplify the creation, training and iterations of AI models. It can load, analyze and explore datasets from the TorchVision or TorchAudio categories, or custom datasets with any format and number of inputs and outputs. TorchVision, TorchAudio or custom models can then be loaded or written from scratch, debugged, visualized as a graph, and trained using local hardware, a distant server or GPUs in the cloud. Trainings can then be compared in the dashboard with several analyzing tools to help you identify the best performing set of models and hyper parameters and export it as TorchScript or ONNX files. TorchStudio is also highly customizable, with 90% of its functionalities accessible as open source scripts and independent modules, to fit as many AI scenario as possible.
  link: https://torchstudio.ai/
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A10.png 
  section: A10
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A10-thumb.png  
  title: "TorchStudio, a full featured IDE for PyTorch"
- authors:
  - Mark Saroufim
  - Hamid Shojanazeri
  - Patrick Hu
  - Geeta Chauhan
  - Jing Xu
  - Jianan Gu
  - Jiong Gong
  - Ashok Emani
  - Eikan Wang
  - Min Jean Cho
  - Fan Zhao
  categories:
  - ACCELERATORS, TOOLS, LIBRARY, DATA
  description: "Accelerate TorchServe with Intel® Extension for PyTorch: Intel is collaborating with Meta to take advantage of performance boosting from Intel® Extension for PyTorch* from TorchServe, so that users can easily deploy their PyTorch models with out of the box satisfying performance. With these SW advancements, we demonstrated ease-of-use IPEX user-facing API, and we also showcased speed-up with Intel® Extension for PyTorch* FP32 inference with the stock PyTorch and speed-up with Intel® Extension for PyTorch* INT8 inference with the stock PyTorch."
  link: www.intel.com/Performanceindex
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A9.png 
  section: A9
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A9-thumb.png  
  title: "Accelerate TorchServe with Intel Extension for PyTorch"
# - authors:
#   - Isaac Godfried
#   - Anton Polishko
#   categories:
#   - ACCELERATORS, TOOLS, LIBRARY, DATA
#   description: Flow Forecast is a multi-purpose open-source deep learning for time series forecasting, classification, and anomaly detection framework built in PyTorch. Flow Forecast utilizes modular code design, unit/integration tests, model/prediction visualizations, and native cloud provider integration in order to allow researchers to rapidly experiment with new model architectures, benchmark their results on popular datasets and reproduce their results. Simultaneously it aids industry data scientists to deploy models to production, periodically retrain models, and explain model decisions to stakeholders through easy to use APIs, out of the box interpretability methods (e.g. SHAP), and model deployment support. Flow Forecast supports a broad variety of deep time series models such as LSTMs, GRUs, Transformers, and GNNs. It also features easy multitask learning support and loaders to help with geo-spatial-temporal data.
#   link: https://github.com/AIStream-Peelout/flow-forecast
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A8.png 
#   section: A8
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A8-thumb.png  
#   title: "Flow Forecast: A deep learning for time series forecasting , classification , and anomaly detection framework"
# - authors:
#   - Patrick Kidger
#   categories:
#   - ACCELERATORS, TOOLS, LIBRARY, DATA
#   description: "Turn this:
#     ```
#     def batch_outer_product(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
#     # x has shape (batch, x_channels)
#     # y has shape (batch, y_channels)
#     # return has shape (batch, x_channels, y_channels)

#     return x.unsqueeze(-1) * y.unsqueeze(-2)
#     ```
#     into this:
#     ```
#     def batch_outer_product(x: TensorType[\"\"batch\"\", \"\"x_channels\"\"],
#     y: TensorType[\"\"batch\"\", \"\"y_channels\"\"]
#     ) -> TensorType[\"\"batch\"\", \"\"x_channels\"\", \"\"y_channels\"\"]:

#     return x.unsqueeze(-1) * y.unsqueeze(-2)
#     ```
#     with programmatic checking that the shape (dtype, ...) specification is met!

#     Bye-bye bugs -- say hello to enforced, clear documentation of PyTorch code.
#     torchtyping may be used instead of littering code with comments like `# x has shape (batch, hidden_state)` or statements like `assert x.shape == y.shape`, just to keep track of what shape/dtype/etc everything is."
#   link: https://github.com/patrick-kidger/torchtyping
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A7.png 
#   section: A7
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A7-thumb.png  
#   title: "TorchTyping: rich type annotations of shape, dtype, etc…"
# - authors:
#   - Yashl Kanungo
#   - Sumit Negi
#   categories:
#   - ACCELERATORS, TOOLS, LIBRARY, DATA
#   description: "Amazon Ads helps companies build their brand and connect with shoppers, through ads shown both within and beyond Amazon’s store, including websites, apps, and streaming TV content in more than 15 countries. Businesses or brands of all sizes including registered sellers, vendors, book vendors, Kindle Direct Publishing (KDP) authors, app developers, and agencies on Amazon marketplaces can upload their own ad creatives, which can include images, video, audio, and of course products sold on Amazon. For our text ad processing, we deploy PyTorch based BERT models globally on AWS Inferentia based Inf1 instances. By moving to Inferentia from GPUs, we were able to lower our cost by 69% with comparable performance."
#   link: https://aws.amazon.com/blogs/aws/scaling-ad-verification-with-machine-learning-and-aws-inferentia/
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A6.png 
#   section: A6
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A6-thumb.png  
#   title: Scaling Ad Classification with Machine Learning on PyTorch and AWS Inferentia
# - authors:
#   - Bharath Ramsundar
#   categories:
#   - ACCELERATORS, TOOLS, LIBRARY, DATA
#   description: "DeepChem uses PyTorch to implement a number of scientific deep learning models for use in modeling proteins, small molecules, materials and physical simulations. DeepChem aims to become a powerful domain specific language for scientific applications that leverages PyTorch to provide a solid base for our models."
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A5.png 
#   section: A5
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A5-thumb.png  
#   title: "DeppChem: A Toolbox for AI driven Science"
# - authors:
#   - Clement Fuji Tsang
#   - Jean-Francois Lafleche
#   - Charles Loop
#   - Masha Shugrina
#   - Towaki Takikawa
#   - Jiehan Wang
#   categories:
#   - ACCELERATORS, TOOLS, LIBRARY, DATA
#   description: "NVIDIA Kaolin is a suite of tools for accelerating 3D Deep Learning research. The Kaolin library provides a PyTorch API for working with a variety of 3D representations and includes a growing collection of GPU-optimized operations such as modular differentiable rendering, fast conversions between representations, loss functions, data loading, 3D checkpoints and more. The library also contains a lightweight 3D visualizer Dash3D and can work with an Omniverse companion app for dataset/checkpoint visualization and synthetic data generation."
#   link:
#   poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A3.png 
#   section: A3
#   thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A3-thumb.png  
#   title: Kaolin Library
- authors:
  - Jack Cao
  - Milad Mohammadi
  - Zak Stone
  - Vaibhav Singh
  - Calvin Pelletier
  - Shauheen Zahirazami
  categories:
  - ACCELERATORS, TOOLS, LIBRARY, DATA
  description: "PyTorch / XLA offers PyTorch users the ability to train their models on XLA devices including Cloud TPUs. This compiled path often makes it possible to utilize creative optimizations and achieve top performance on target XLA devices. With the introduction of Cloud TPU VMs, users have direct access to TPU host machines and therefore a great level of flexibility. In addition, TPU VMs make debugging easier and reduce data transfer overheads. Google has also recently announced the availability of Cloud TPU v4 Pods, which are exaflop-scale supercomputers for machine learning. Cloud TPU v4 Pods offer a whole new level of performance for large-scale PyTorch / XLA training of ML models."
  link:
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A2.png
  section: A2
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A2-thumb.png
  title: Accelerate PyTorch training with Cloud TPUs
- authors:
  - Antonio Kim
  - Behzad Abghari
  - Chris Oliver
  - Cynthia Liu
  - Mark Browning
  - Vishal Subbiah
  - Kamran Jafari
  - Emad Barsoum
  - Jessica Liu
  - Sean Lie
  categories:
  - ACCELERATORS, TOOLS, LIBRARY, DATA
  description: "The Cerebras Wafer Scale Engine (WSE) is the largest processor ever built, dedicated to accelerating deep learning model for training and inference. A single chip in a single CS-2 system provides the compute power of a cluster of GPUs but acts as a single processor, making it also much simpler to use. We present the current PyTorch backend architecture for the Cerebras CS-2 and how we go all the way from PyTorch to laying out the model graph on the wafer. Additionally, we will discuss the advantages of training on Cerebras hardware and its unique capabilities."
  link: https://cerebras.net 
  poster_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A1.png
  section: A1
  thumbnail_link: https://s3.amazonaws.com/assets.pytorch.org/ptdd2021/posters/A1-thumb.png
  title: Accelerating PyTorch on the largest chip ever built (WSE)
- authors:
  - Josh Izaac
  - Thomas Bromley
  categories:
  - Platform, Ops & Tools
  description: "PennyLane allows you to train quantum circuits just like neural networks!,\
    \ This poster showcases how PennyLane can be interfaced with PyTorch to enable\
    \ training of quantum and hybrid machine learning models. The outputs of a quantum\
    \ circuit are provided as a Torch tensor with a defined gradient. We highlight how\
    \ this functionality can be used to explore new paradigms in machine learning, including\
    \ the use of hybrid models for transfer learning."
  link: http://www.pennylane.ai 
  poster_link: https://assets.pytorch.org/pted2021/posters/K1.png
  section: K1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K1.png
  title: Bring quantum machine learning to PyTorch with PennyLane
- authors:
  - Jeffrey Mew
  categories:
  - Compiler & Transform & Production
  description: "Visual Studio Code, a free cross-platform lightweight code editor,\
    \ has become the most popular among Python developers for both web and machine\
    \ learning projects. We will be walking you through an end to end PyTorch project\
    \ to showcase what VS Code has a lot to offer to PyTorch developers to boost their\
    \ productivity.\n \nFirstly, get your PyTorch project quickly up and running with\
    \ VS Code's environment/dependency management and built-in Jupyter Notebook support.\
    \ Secondly, breeze through coding with help from our AI-powered IntelliSense.\
    \ When it's time to run your code, use the built-in Tensorboard integration to\
    \ monitor your training along with the integrated PyTorch profiler to analyze\
    \ and debug your code. Once you're ready for the cloud, VS Code has Azure service\
    \ integration to allow you to scale your model training and deployment, along\
    \ with deployment.\n \nCombing the power of the code editor with easy access to\
    \ the Azure services, VS Code can be the one-stop shop for any developers looking\
    \ to build machine learning models with PyTorch."
  link: https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/
  poster_link: https://assets.pytorch.org/pted2021/posters/A4.png
  section: A4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A4.png
  title: PyTorch development in VS Code
- authors:
  - Yanan Cao
  - Harry Kim
  - Jason Ansel
  categories:
  - Compiler & Transform & Production
  description: TorchScript is the bridge between PyTorch's flexible eager mode to
    more deterministic and performant graph mode suitable for production deployment.
    As part of PyTorch 1.9 release, TorchScript will launch a few features that we'd
    like to share with you earlier, including a) a new formal language specification
    that defines the exact subset of Python/PyTorch features supported in TorchScript;
    b) Profile-Directed Typing that reduces the burden of converting a loosely-typed
    eager model into a strictly-typed TorchScript model; c) A TorchScript profiler
    that can shed light on performance characteristics of TorchScript model. We are
    constantly making improvements to make TorchScript easier to use and more performant.
  link: http://fb.me/torchscript
  poster_link: https://assets.pytorch.org/pted2021/posters/A5.png
  section: A5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A5.png
  title: Upcoming features in TorchScript
- authors:
  - Alessandro Pappalardo
  categories:
  - Compiler & Transform & Production
  description: Brevitas is an open-source PyTorch library for quantization-aware training.
    Thanks to its flexible design at multiple levels of abstraction, Brevitas generalizes
    the typical uniform affine quantization paradigm adopted in the deep learning
    community under a common set of unified APIs. Brevitas provides a platform to
    both ML practitioners and researchers to either apply built-in state-of-the-art
    techniques in training for reduced-precision inference, or to implement novel
    quantization-aware training algorithms. Users can target supported inference toolchains,
    such as onnxruntime, TVM, Vitis AI, FINN or PyTorch itself, or experiment with
    hypothetical target hardware platforms. In particular, when combined with the
    flexibility of Xilinx FPGAs through the FINN toolchain, Brevitas supports the
    co-design of novel hardware building blocks in a machine-learning driven fashion.
    Within Xilinx, Brevitas has been adopted by various research projects concerning
    quantized neural networks, as well as in large scale deployments targeting custom
    programmable logic accelerators.
  link: https://github.com/Xilinx/brevitas/
  section: B4
  title: Quantization-Aware Training with Brevitas
- authors:
  - Jerry Zhang
  - Vasiliy Kuznetsov
  - Raghuraman Krishnamoorthi
  categories:
  - Compiler & Transform & Production
  description: Quantization is a common model optimization technique to speedup runtime
    of a model by upto 4x,  with a possible slight loss of accuracy. Currently, PyTorch
    support Eager Mode Quantization. FX Graph Mode Quantization improves upon Eager
    Mode Quantization by adding support for functionals and automating the quantization
    process. To use FX Graph Mode Quantization, one might need to refactor the model
    to make the model compatible with FX Graph Mode Quantization (symbolically traceable
    with torch.fx).
  link: https://pytorch.org/docs/master/quantization.html#prototype-fx-graph-mode-quantization
  poster_link: https://assets.pytorch.org/pted2021/posters/B5.png
  section: B5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-B5.png
  title: 'PyTorch Quantization: FX Graph Mode Quantization'
- authors:
  - Fabio Nonato
  categories:
  - Compiler & Transform & Production
  description: " Deep learning models can have game-changing impact on machine learning\
    \ applications. However, deploying and managing deep learning models in production\
    \ is complex and requires considerable engineering effort - from  building custom\
    \ inferencing APIs and scaling prediction services, to securing applications,\
    \ while still leveraging the latest ML frameworks and hardware technology.  Amazon\
    \ EC2 Inf1 instances powered by AWS Inferentia deliver the highest performance\
    \ and lowest cost machine learning inference in the cloud. Developers can deploy\
    \ their deep-learning models to Inf1 instances using the AWS Neuron SDK that is\
    \ natively integrated with PyTorch.\n \nAttend this poster session to learn how\
    \ you can optimize and accelerate the deployment of your deep learning models\
    \ in production using Inf1 instances and TorchServe containers. You will learn\
    \ how to deploy TorchScript models on Inf1 and optimize your models with minimal\
    \ code changes with features such as NeuronCore Groups and NeuronCore Pipeline,\
    \ to meet your throughput and latency requirements. You can directly integrate\
    \ these model level optimizations into the inference endpoint using TorchServe.\n\
    \ \nWe will also deep dive into how we optimized performance of  a natural language\
    \ processing endpoint and showcase the workflow for deploying the optimized model\
    \ using TorchServe containers on Amazon ECS."
  link: https://bit.ly/3mQVowk
  poster_link: https://assets.pytorch.org/pted2021/posters/C4.png
  section: C4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C4.png
  title: Accelerate deployment of deep learning models in production with Amazon EC2
    Inf1 and TorchServe containers
- authors:
  - James Reed
  - Zachary DeVito
  - Ansley Ussery
  - Horace He
  - Michael Suo
  categories:
  - Compiler & Transform & Production
  description: "FX is a toolkit for writing Python-to-Python transforms over PyTorch\
    \ code.\nFX consists of three parts:\n> Symbolic Tracing \u2013 a method to extract\
    \ a representation of the program by running it with \"proxy\" values.\n> Graph-based\
    \ Transformations \u2013 FX provides an easy-to-use Python-based Graph API for\
    \ manipulating the code.\n> Python code generation \u2013 FX generates valid Python\
    \ code from graphs and turns that code into executable Python `nn.Module` instances."
  link: https://pytorch.org/docs/stable/fx.html
  poster_link: https://assets.pytorch.org/pted2021/posters/C5.png
  section: C5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C5.png
  title: Torch.fx
- authors:
  - Abhijit Khobare
  - Murali Akula
  - Tijmen Blankevoort
  - Harshita Mangal
  - Frank Mayer
  - Sangeetha Marshathalli Siddegowda
  - Chirag Patel
  - Vinay Garg
  - Markus Nagel
  categories:
  - Compiler & Transform & Production
  description: 'AI is revolutionizing industries, products, and core capabilities
    by delivering dramatically enhanced experiences. However, the deep neural networks
    of today use too much memory, compute, and energy. To make AI truly ubiquitous,
    it needs to run on the end device within a tight power and thermal budget. Quantization
    and compression help address these issues. In this tutorial, we''ll discuss:

    The existing quantization and compression challenges

    Our research in novel quantization and compression techniques to overcome these
    challenges

    How developers and researchers can implement these techniques through the AI Model
    Efficiency Toolkit'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/D4.png
  section: D4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D4.png
  title: AI Model Efficiency Toolkit (AIMET)
- authors:
  - Natasha Seelam
  - Patricio Cerda-Mardini
  - Cosmo Jenytin
  - Jorge Torres
  categories:
  - Database & AI Accelerators
  description: 'Pytorch enables building models with complex inputs and outputs, including
    time-series data, text and audiovisual data. However, such models require expertise
    and time to build, often spent on tedious tasks like cleaning the data or transforming
    it into a format that is expected by the models.


    Thus, pre-trained models are often used as-is when a researcher wants to experiment
    only with a specific facet of a problem. See, as examples, FastAI''s work into
    optimizers, schedulers, and gradual training through pre-trained residual models,
    or NLP projects with Hugging Face models as their backbone.


    We think that, for many of these problems, we can automatically generate a "good
    enough" model and data-processing pipeline from just the raw data and the endpoint.
    To address this situation, we are developing MindsDB, an open-source, PyTorch-based
    ML platform that works inside databases via SQL commands. It is built with a modular
    approach, and in this talk we are going to focus on Lightwood, the stand-alone
    core component that performs machine learning automation on top of the PyTorch
    framework.


    Lightwood automates model building into 5 stages: (1) classifying each feature
    into a "data type", (2) running statistical analyses on each column of a dataset,
    (3) fitting multiple models to normalize, tokenize, and generate embeddings for
    each feature, (4) deploying the embeddings to fit a final estimator, and (5) running
    an analysis on the final ensemble to evaluate it and generate a confidence model.
    It can generate quick "baseline" models to benchmark performance for any custom
    encoder representation of a data type and can also serve as scaffolding for investigating
    new hypotheses (architectures, optimizers, loss-functions, hyperparameters, etc).


    We aim to present our benchmarks covering wide swaths of problem types and illustrate
    how Lightwood can be useful for researchers and engineers through a hands-on demo.'
  link: https://mindsdb.com
  poster_link: https://assets.pytorch.org/pted2021/posters/H8.png
  section: H8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H8.png
  title: 'Pytorch via SQL commands: A flexible, modular AutoML framework that democratizes
    ML for database users'
- authors:
  - 'Sam Partee '
  - Alessandro Rigazzi
  - Mathew Ellis
  - Benjamin Rob
  categories:
  - Database & AI Accelerators
  description: SmartSim is an open source library dedicated to enabling online analysis
    and Machine Learning (ML) for traditional High Performance Computing (HPC) simulations.
    Clients are provided in common HPC simulation languages, C/C++/Fortran, that enable
    simulations to perform inference requests in parallel on large HPC systems. SmartSim
    utilizes the Redis ecosystem to host and serve PyTorch models alongside simulations.
    We present a use case of SmartSim where a global ocean simulation, used in climate
    modeling, is augmented with a PyTorch model to resolve quantities of eddy kinetic
    energy within the simulation.
  link: https://github.com/CrayLabs/SmartSim
  poster_link: https://assets.pytorch.org/pted2021/posters/J8.png
  section: J8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J8.png
  title: PyTorch on Supercomputers Simulations and AI at Scale with SmartSim
- authors:
  - Patricio Cerda-Mardini
  - Natasha Seelam
  categories:
  - Database & AI Accelerators
  description: 'Many domains leverage the extraordinary predictive performance of
    machine learning algorithms. However, there is an increasing need for transparency
    of these models in order to justify deploying them in applied settings. Developing
    trustworthy models is a great challenge, as they are usually optimized for accuracy,
    relegating the fit between the true and predicted distributions to the background
    [1]. This concept of obtaining predicted probability estimates that match the
    true likelihood is also known as calibration.


    Contemporary ML models generally exhibit poor calibration. There are several methods
    that aim at producing calibrated ML models [2, 3]. Inductive conformal prediction
    (ICP) is a simple yet powerful framework to achieve this, offering strong guarantees
    about the error rates of any machine learning model [4]. ICP provides confidence
    scores and turns any point prediction into a prediction region through nonconformity
    measures, which indicate the degree of inherent strangeness a data point presents
    when compared to a calibration data split.


    In this work, we discuss the integration of ICP with MindsDB --an open source
    AutoML framework-- successfully replacing its existing quantile loss approach
    for confidence estimation capabilities.

    Our contribution is threefold. First, we present a study on the effect of a "self-aware"
    neural network normalizer in the width of predicted region sizes (also known as
    efficiency) when compared to an unnormalized baseline. Our benchmarks consider
    results for over 30 datasets of varied domains with both categorical and numerical
    targets. Second, we propose an algorithm to dynamically determine the confidence
    level based on a target size for the predicted region, effectively prioritizing
    efficiency over a minimum error rate. Finally, we showcase the results of a nonconformity
    measure specifically tailored for small datasets.


    References:

    [1] Guo, C., Pleiss, G., Sun, Y., & Weinberger, K.Q. (2017). On Calibration of
    Modern Neural Networks. ArXiv, abs/1706.04599.

    [2] Naeini, M., Cooper, G., & Hauskrecht, M. (2015). Obtaining Well Calibrated
    Probabilities Using Bayesian Binning. Proceedings of the AAAI Conference on Artificial
    Intelligence. AAAI Conference on Artificial Intelligence, 2015, 2901-2907 .

    [3] Maddox, W., Garipov, T., Izmailov, P., Vetrov, D., & Wilson, A. (2019). A
    Simple Baseline for Bayesian Uncertainty in Deep Learning. NeurIPS.

    [4] Papadopoulos, H., Vovk, V., & Gammerman, A. (2007). Conformal Prediction with
    Neural Networks. 19th IEEE International Conference on Tools with Artificial Intelligence
    (ICTAI 2007), 2, 388-395.'
  link: https://mindsdb.com
  poster_link: https://assets.pytorch.org/pted2021/posters/I8.png
  section: I8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I8.png
  title: Model agnostic confidence estimation with conformal predictors for AutoML
- authors:
  - Derek Bouius
  categories:
  - Database & AI Accelerators
  description: AMD Instinct GPUs are enabled with the upstream PyTorch repository
    via the ROCm open software platform. Now users can also easily download the installable
    Python package, built from the upstream PyTorch repository and hosted on pytorch.org.
    Notably, it includes support for distributed training across multiple GPUs and
    supports accelerated mixed precision training. AMD also provides hardware support
    for the PyTorch community build to help develop and maintain new features. This
    poster will highlight some of the work that has gone into enabling PyTorch support.
  link: www.amd.com/rocm
  poster_link: https://assets.pytorch.org/pted2021/posters/K8.png
  section: K8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K8.png
  title: "Enabling PyTorch on AMD Instinct\u2122 GPUs with the AMD ROCm\u2122 Open\
    \ Software Platform"
- authors:
  - DeepSpeed Team Microsoft Corporation
  categories:
  - Distributed Training
  description: 'In the poster (and a talk during the breakout session), we will present
    three aspects of DeepSpeed (https://github.com/microsoft/DeepSpeed), a deep learning
    optimization library based on PyTorch framework: 1) How we overcome the GPU memory
    barrier by ZeRO-powered data parallelism. 2) How we overcome the network bandwidth
    barrier by 1-bit Adam and 1-bit Lamb compressed optimization algorithms. 3) How
    we overcome the usability barrier by integration with Azure ML, HuggingFace, and
    PyTorch Lightning.'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/E1.png
  section: E1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-E1.png
  title: 'DeepSpeed: Shattering barriers of deep learning speed & scale'
- authors:
  - Stephanie Kirmer
  - Hugo Shi
  categories:
  - Distributed Training
  description: We have developed a library that helps simplify the task of multi-machine
    parallel training for PyTorch models, bringing together the power of PyTorch DDP
    with Dask for parallelism on GPUs. Our poster describes the library and its core
    function, and demonstrates how the multi-machine training process works in practice.
  link: https://github.com/saturncloud/dask-pytorch-ddp
  section: E2
  title: 'Dask PyTorch DDP: A new library bringing Dask parallelization to PyTorch
    training'
- authors:
  - Vignesh Gopakumar
  categories:
  - Distributed Training
  description: Solving PDEs using Neural Networks are often ardently laborious as
    it requires training towards a well-defined solution, i.e. global minima for a
    network architecture - objective function combination. For a family of complex
    PDEs, Physics Informed neural networks won't offer much in comparison to traditional
    numerical methods as their global minima becomes more and more intractable. We
    propose a modified approach that hinges on continual and parametrised learning
    that can create more general PINNs that can solve for a variety of PDE scenarios
    rather than solving for a well-defined case. We believe that this brings Neural
    Network based PDE solvers in comparison to numerical solvers.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/E3.png
  section: E3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-E3.png
  title: Optimising Physics Informed Neural Networks.
- authors:
  - Mandeep Baines
  - Shruti Bhosale
  - Vittorio Caggiano
  - Benjamin Lefaudeux
  - Vitaliy Liptchinsky
  - Naman Goyal
  - Siddhardth Goyal
  - Myle Ott
  - Sam Sheifer
  - Anjali Sridhar
  - Min Xu
  categories:
  - Distributed Training
  description: 'FairScale is a library that extends basic PyTorch capabilities while
    adding new SOTA techniques for high performance and large scale training on one
    or multiple machines. FairScale makes available the latest distributed training
    techniques in the form of composable modules and easy to use APIs.


    Machine Learning (ML) training at scale traditionally means data parallelism to
    reduce training time by using multiple devices to train on larger batch size.
    Nevertheless, with the recent increase of ML models sizes data parallelism is
    no longer enough to satisfy all "scaling" needs. FairScale provides several options
    to overcome some of the limitations to scale.


    For scaling training that is bottlenecked by memory (optimizer state, intermediate
    activations, parameters), FairScale provides APIs that have implemented optimizer,
    gradient and parameter sharding. This will allow users to train large models using
    devices in a more memory efficient manner.


    To overcome the memory required for large models FairScale provides various flavors
    of pipeline and model parallelism, MOE (Mixture Of Experts) layer, and Offload
    models. Those methods allow to perform computation only of shards of the models
    across multiple devices with micro batches of data to maximize device efficiency.


    FairScale also provides modules to aid users to scale batch size effectively without
    changing their existing learning rate hyperparameter - AdaScale - and save memory
    with checkpoint activation of intermediate layers.


    FairScale has also been integrated into Pytorch Lightening, HuggingFace, FairSeq,
    VISSL, and MMF to enable users of those frameworks to take advantage of its features.'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/F1.png
  section: F1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-F1.png
  title: FairScale-A general purpose modular PyTorch library for  high performance
    and large scale training
- authors:
  - Aurick Qiao
  - Sang Keun Choe
  - Suhas Jayaram Subramanya
  - Willie Neiswanger
  - Qirong Ho
  - Hao Zhang
  - Gregory R. Ganger
  - Eric P. Xing
  categories:
  - Distributed Training
  description: 'AdaptDL is an open source framework and scheduling algorithm that
    directly optimizes cluster-wide training performance and resource utilization.
    By elastically re-scaling jobs, co-adapting batch sizes and learning rates, and
    avoiding network interference, AdaptDL improves shared-cluster training compared
    with alternative schedulers. AdaptDL can automatically determine the optimal number
    of resources given a job''s need. It will efficiently add or remove resources
    dynamically to ensure the highest-level performance. The AdaptDL scheduler will
    automatically figure out the most efficient number of GPUs to allocate to your
    job, based on its scalability. When the cluster load is low, your job can dynamically
    expand to take advantage of more GPUs. AdaptDL offers an easy-to-use API to make
    existing PyTorch training code elastic with adaptive batch sizes and learning
    rates.

    Showcase: Distributed training and Data Loading'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/F2.png
  section: F2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-F2.png
  title: 'AdaptDL: An Open-Source Resource-Adaptive Deep Learning Training/Scheduling
    Framework'
- authors:
  - Natalie Kershaw
  categories:
  - Distributed Training
  description: 'As deep learning models, especially transformer models get bigger
    and bigger, reducing training time becomes both a financial and environmental
    imperative. ONNX Runtime can accelerate large-scale distributed training of PyTorch
    transformer models with a one-line code change (in addition to import statements
    ;-)) Adding in the DeepSpeed library improves training speed even more.


    With the new ORTModule API, you wrap an existing torch.nn.Module, and have us
    automatically: export the model as an ONNX computation graph; compile and optimize
    it with ONNX Runtime; and integrate it into your existing training script.


    In this poster, we demonstrate how to fine-tune a popular HuggingFace model and
    show the performance improvement, on a multi-GPU cluster in the Azure Machine
    Learning cloud service.'
  link: https://aka.ms/pytorchort
  section: G1
  title: 'Accelerate PyTorch large model training with ONNX Runtime: just add one
    line of code!'
- authors:
  - Jack Cao
  - Daniel Sohn
  - Zak Stone
  - Shauheen Zahirazami
  categories:
  - Distributed Training
  description: PyTorch / XLA enables users to train PyTorch models on XLA devices
    including Cloud TPUs. Cloud TPU VMs now provide direct access to TPU host machines
    and hence offer much greater flexibility in addition to making debugging easier
    and reducing data transfer overheads. PyTorch / XLA has now full support for this
    new architecture. A new profiling tool has also been developed to enable better
    profiling of PyTorch / XLA. These improvements not only make it much easier to
    develop models but also reduce the cost of large-scale PyTorch / XLA training
    runs on Cloud TPUs.
  link: http://goo.gle/pt-xla-tpuvm-signup
  poster_link: https://assets.pytorch.org/pted2021/posters/G2.png
  section: G2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-G2.png
  title: PyTorch/XLA with new Cloud TPU VMs and Profiler
- authors:
  - Ari Bornstein
  categories:
  - Frontend & Experiment Manager
  description: PyTorch Lightning reduces the engineering boilerplate and resources
    required to implement state-of-the-art AI. Organizing PyTorch code with Lightning
    enables seamless training on multiple-GPUs, TPUs, CPUs, and the use of difficult
    to implement best practices such as model sharding, 16-bit precision, and more,
    without any code changes. In this poster, we will use practical Lightning examples
    to demonstrate how to train Deep Learning models with less boilerplate.
  link: https://www.pytorchlightning.ai/
  poster_link: https://assets.pytorch.org/pted2021/posters/E4.png
  section: E4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-E4.png
  title: 'PyTorch Lightning: Deep Learning without the Boilerplate'
- authors:
  - Jiong Gong
  - Nikita Shustrov
  - Eikan Wang
  - Jianhui Li
  - Vitaly Fedyunin
  categories:
  - Frontend & Experiment Manager
  description: "Intel and Facebook collaborated to enable BF16, a first-class data\
    \ type in PyTorch, and a data type that are accelerated natively with the 3rd\
    \ Gen Intel\xAE Xeon\xAE scalable processors. This poster introduces the latest\
    \ SW advancements added in Intel Extension for PyTorch (IPEX) on top of PyTorch\
    \ and the oneAPI DNN library for ease-of-use and high-performance BF16 DL compute\
    \ on CPU. With these SW advancements, we demonstrated ease-of-use IPEX user-facing\
    \ API, and we also showcased 1.55X-2.42X speed-up with IPEX BF16 training over\
    \ FP32 with the stock PyTorch and 1.40X-4.26X speed-up with IPEX BF16 inference\
    \ over FP32 with the stock PyTorch."
  link: https://github.com/intel/intel-extension-for-pytorch
  poster_link: https://assets.pytorch.org/pted2021/posters/E5.png
  section: E5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-E5.png
  title: Accelerate PyTorch with IPEX and oneDNN using Intel BF16 Technology
- authors:
  - Robin Lobel
  categories:
  - Frontend & Experiment Manager
  description: TorchStudio is a standalone software based on PyTorch and LibTorch.
    It aims to simplify the creation, training and iterations of PyTorch models. It
    runs locally on Windows, Ubuntu and macOS. It can load, analyze and explore PyTorch
    datasets from the TorchVision or TorchAudio categories, or custom datasets with
    any number of inputs and outputs. PyTorch models can then be loaded and written
    from scratch, analyzed, and trained using local hardware. Trainings can be run
    simultaneously and compared to identify the best performing models, and export
    them as a trained TorchScript or ONNX model.
  link: https://torchstudio.ai/
  poster_link: https://assets.pytorch.org/pted2021/posters/F4.png
  section: F4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-F4.png
  title: TorchStudio, a machine learning studio software based on PyTorch
- authors:
  - Jieru Hu
  - 'Omry Yadan '
  categories:
  - Frontend & Experiment Manager
  description: 'Hydra is an open source framework for configuring and launching research
    Python applications. Key features: - Compose and override your config dynamically
    to get the perfect config for each run - Run on remote clusters like SLURM and
    AWS without code changes - Perform basic greed search and hyper parameter optimization
    without code changes - Command line tab completion for your dynamic config And
    more.'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/F5.png
  section: F5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-F5.png
  title: Hydra Framework
- authors:
  - Victor Fomin
  - Sylvain Desroziers
  - Taras Savchyn
  categories:
  - Frontend & Experiment Manager
  description: This poster intends to give a brief but illustrative overview of what
    PyTorch-Ignite can offer for Deep Learning enthusiasts, professionals and researchers.
    Following the same philosophy as PyTorch, PyTorch-Ignite aims to keep it simple,
    flexible and extensible but performant and scalable. Throughout this poster, we
    will introduce the basic concepts of PyTorch-Ignite, its API and features it offers.
    We also assume that the reader is familiar with PyTorch.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/G4.png
  section: G4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-G4.png
  title: 'PyTorch-Ignite: training common things easy and the hard things possible'
- authors:
  - Sanzhar Askaruly
  - Nurbolat Aimakov
  - Alisher Iskakov
  - Hyewon Cho
  categories:
  - Medical & Healthcare
  description: Deep learning has transformed many aspects of industrial pipelines
    recently. Scientists involved in biomedical imaging research are also benefiting
    from the power of AI to tackle complex challenges. Although the academic community
    has widely accepted image processing tools, such as scikit-image, ImageJ, there
    is still a need for a tool which integrates deep learning into biomedical image
    analysis. We propose a minimal, but convenient Python package based on PyTorch
    with common deep learning models, extended by flexible trainers and medical datasets.
  link: https://github.com/tuttelikz/farabio
  poster_link: https://assets.pytorch.org/pted2021/posters/H4.png
  section: H4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H4.png
  title: Farabio - Deep Learning Toolkit for Biomedical Imaging
- authors:
  - Michael Zephyr
  - Prerna Dogra Richard Brown
  - Wenqi Li
  - Eric Kerfoot
  categories:
  - Medical & Healthcare
  description: "Healthcare image analysis for both radiology and pathology is increasingly\
    \ being addressed with deep-learning-based solutions. These applications have\
    \ specific requirements to support various imaging modalities like MR, CT, ultrasound,\
    \ digital pathology, etc. It is a substantial effort for researchers in the field\
    \ to develop custom functionalities to handle these requirements. Consequently,\
    \ there has been duplication of effort, and as a result, researchers have incompatible\
    \ tools, which makes it hard to collaborate.\n \nMONAI stands for Medical Open\
    \ Network for AI. Its mission is to accelerate the development of healthcare imaging\
    \ solutions by providing domain-specialized building blocks and a common foundation\
    \ for the community to converge in a native PyTorch paradigm."
  link: https://monai.io/
  poster_link: https://assets.pytorch.org/pted2021/posters/H5.png
  section: H5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H5.png
  title: 'MONAI: A Domain Specialized Library for Healthcare Imaging'
- authors:
  - Shai Brown
  - Daniel Neimark
  - Maya Zohar
  - Omri Bar
  - Dotan Asselmann
  categories:
  - Medical & Healthcare
  description: "Theator is re-imagining surgery with a Surgical Intelligence platform\
    \ that leverages highly advanced AI, specifically machine learning and computer\
    \ vision technology, to analyze every step, event, milestone, and critical junction\
    \ of surgical procedures.\n\nOur platform analyzes lengthy surgical procedure\
    \ videos and extracts meaningful information, providing surgeons with highlight\
    \ reels of key moments in an operation, enhanced by annotations.\n\nAs the team\
    \ expanded, we realized that we were spending too much time manually running model\
    \ training and focusing on DevOps tasks and not enough time dedicated to core\
    \ research.\n\nTo face this, we build an automation framework composed of multiple\
    \ training pipelines using PyTorch and ClearML. Our framework automates and manages\
    \ our entire process, from model development to deployment to continuous training\
    \ for model improvement.\n\nNew data is now immediately processed and fed directly\
    \ into training pipelines \u2013 speeding up workflow, minimizing human error,\
    \ and freeing up our research team for more important tasks. Thus, enabling us\
    \ to scale our ML operation and deliver better models for our end users."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/I4.png
  section: I4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I4.png
  title: How theator Built a Continuous Training Framework to Scale Up Its Surgical
    Intelligence Platform
- authors:
  - Cebere Bogdan
  - Cebere Tudor
  - Manolache Andrei
  - Horia Paul-Ion
  categories:
  - Medical & Healthcare
  description: We present Q&Aid, a conversation agent that relies on a series of machine
    learning models to filter, label, and answer medical questions based on a provided
    image and text inputs. Q&Aid is simplifying the hospital logic backend by standardizing
    it to a Health Intel Provider (HIP). A HIP is a collection of models trained on
    local data that receives text and visual input, afterward filtering, labeling,
    and feeding the data to the right models and generating at the end output for
    the aggregator. Any hospital is identified as a HIP holding custom models and
    labeling based on its knowledge. The hospitals are training and fine-tuning their
    models, such as a Visual Question Answering (VQA) model, on private data (e.g.
    brain anomaly segmentation). We aggregate all of the tasks that the hospitals
    can provide into a single chat app, offering the results to the user. When the
    chat ends, the transcript is forwarded to each hospital, a doctor being in charge
    of the final decision.
  link: https://qrgo.page.link/d1fQk
  poster_link: https://assets.pytorch.org/pted2021/posters/I5.png
  section: I5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I5.png
  title: 'Q&Aid: A Conversation Agent Powered by PyTorch'
- authors:
  - Jaden Hong
  - Kevin Tran
  - Tyler Lee
  - Paul Lee
  - Freddie Cha
  - Louis Jung
  - Dr. Jung Kyung Hong
  - Dr. In-Young Yoon
  - David Lee
  categories:
  - Medical & Healthcare
  description: "Sleep disorders and insomnia are now regarded as a worldwide problem.\
    \ Roughly 62% of adults worldwide feel that they don't sleep well. However, sleep\
    \ is difficult to track so it's not easy to get suitable treatment to improve\
    \ your sleep quality. Currently, the PSG (Polysomnography) is the only way to\
    \ evaluate the sleep quality accurately but it's expensive and often inaccurate\
    \ due to the first night effect. \n\nWe propose a multi-signal sleep stage classifier\
    \ for contactless sleep tracking: Sleepbot. By automating the manual PSG reading\
    \ and providing explainable analysis, Sleepbot opens a new possibility to apply\
    \ sleep staging AI in both home and hospital. With sound recorded by a smartphone\
    \ app and RF-sensed signal measured by Asleep's non-contact sleep tracker, Sleepbot\
    \ provides a clinical level of sleep stage classification. \n\nSleepbot achieved\
    \ 85.5 % accuracy in 5-class (Wake, N1, N2, N3, Rem) using PSG signals measured\
    \ from 3,700 subjects and 77 % accuracy in 3-class (Wake, Sleep, REM) classification\
    \ using only sound data measured from 1,2000 subjects."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/J4.png
  section: J4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J4.png
  title: 'Sleepbot: Multi-signal Sleep Stage Classifier AI for hospital and home'
- authors:
  - Akshay Agrawal
  - Alnur Ali
  - Stephen Boyd
  categories:
  - Medical & Healthcare
  description: 'We present a unifying framework for the vector embedding problem:
    given a set of items and some known relationships between them, we seek a representation
    of the items by vectors, possibly subject to some constraints (e.g., requiring
    the vectors to have zero mean and identity covariance). We want the vectors associated
    with similar items to be near each other, and vectors associated with dissimilar
    items to not be near, measured in Euclidean distance. We formalize this by introducing
    distortion functions, defined for some pairs of the items. Our goal is to choose
    an embedding that minimizes the total distortion, subject to the constraints.
    We call this the minimum-distortion embedding (MDE) problem. The MDE framework
    generalizes many well-known embedding methods, such as PCA, the Laplacian eigenmap,
    multidimensional scaling, UMAP, and others, and also includes new types of embeddings.


    Our accompanying software library, PyMDE, makes it easy for users to specify and
    approximately solve MDE problems, enabling experimentation with well-known and
    custom embeddings alike. By making use of automatic differentiation and hardware
    acceleration via PyTorch, we are able to scale to very large embedding problems.
    We will showcase examples of embedding real datasets, including an academic co-authorship
    network, single-cell mRNA transcriptomes, US census data, and population genetics.'
  link: ''
  section: J5
  title: 'PyMDE: Minimum-Distortion Embedding'
- authors:
  - "Fernando P\xE9rez-Garc\xEDa"
  - Rachel Sparks
  - "S\xE9bastien Ourselin"
  categories:
  - Medical & Healthcare
  description: 'Processing of medical images such as MRI or CT presents unique challenges
    compared to RGB images typically used in computer vision. These include a lack
    of labels for large datasets, high computational costs, and metadata to describe
    the physical properties of voxels. Data augmentation is used to artificially increase
    the size of the training datasets. Training with image patches decreases the need
    for computational power. Spatial metadata needs to be carefully taken into account
    in order to ensure a correct alignment of volumes.


    We present TorchIO, an open-source Python library to enable efficient loading,
    preprocessing, augmentation and patch-based sampling of medical images for deep
    learning. TorchIO follows the style of PyTorch and integrates standard medical
    image processing libraries to efficiently process images during training of neural
    networks. TorchIO transforms can be composed, reproduced, traced and extended.
    We provide multiple generic preprocessing and augmentation operations as well
    as simulation of MRI-specific artifacts.


    TorchIO was developed to help researchers standardize medical image processing
    pipelines and allow them to focus on the deep learning experiments. It encourages
    open science, as it supports reproducibility and is version controlled so that
    the software can be cited precisely. Due to its modularity, the library is compatible
    with other frameworks for deep learning with medical images.'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/K4.png
  section: K4
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K4.png
  title: 'TorchIO: Pre-Processing & Augmentation of Medical Images for Deep Learning
    Applications'
- authors:
  - Laila Rasmy
  - Ziqian Xie
  - Degui Zhi
  categories:
  - Medical & Healthcare
  description: With the extensive use of electronic records and the availability of
    historical patient information, predictive models that can help identify patients
    at risk based on their history at an early stage can be a valuable adjunct to
    clinician judgment. Deep learning models can better predict patients' outcomes
    by consuming their medical history regardless of the length and the complexity
    of such data. We used our Pytorch_EHR framework to train a model that can predict
    COVID-19 patient's health outcomes on admission. We used the Cerner Real-world
    COVID-19 (Q2) cohort which included information for 117,496 COVID patients from
    62 health systems. We used a cohort of 55,068 patients and defined our outcomes
    including mortality, intubation, and hospitalization longer than 3 days as binary
    outcomes. We feed the model with all diagnoses, medication, laboratory results,
    and other clinical events information available before or on their first COVID-19
    encounter admission date. We kept the data preprocessing at a minimum for convenience
    and practicality relying on the embedding layer that learns features representations
    from the large training set. Our model showed improved performance compared to
    other baseline machine learning models like logistic regression (LR). For in-hospital
    mortality, our model showed AUROC of 89.5%, 90.6%, and 84.3% for in-hospital mortality,
    intubation, and hospitalization for more than 3 days, respectively versus LR which
    showed 82.8%, 83.2%, and 76.8%
  link: https://github.com/ZhiGroup/pytorch_ehr
  poster_link: https://assets.pytorch.org/pted2021/posters/K5.png
  section: K5
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K5.png
  title: Deep Learning Based Model to Predict Covid19 Patients' Outcomes on Admission
- authors:
  - Binghui Ouyang
  - "Alexander O\u2019Connor "
  categories:
  - NLP & Multimodal, RL & Time Series
  description: "While Transformers have brought unprecedented improvements in the\
    \ accuracy and ease of developing NLP applications, their deployment remains challenging\
    \ due to the large size of the models and their computational complexity. \n Indeed,\
    \ until recently is has been a widespread misconception that hosting high-performance\
    \ transformer-based models was prohibitively expensive, and technically challenging.\
    \ Fortunately, recent advances in both the PyTorch ecosystem and in custom hardware\
    \ for inference have created a world where models can be deployed in a cost-effective,\
    \ scalable way, without the need for complex engineering.\n\nIn this presentation,\
    \ we will discuss the use of PyTorch and AWS Inferentia to deploy production-scale\
    \ models in chatbot intent classification - a particularly relevant and demanding\
    \ scenario. \n\nAutodesk deploys a number of transformer based models to solve\
    \ customer support issues across our channels, and our ability to provide a flexible,\
    \ high-quality machine learning solution is supported by leveraging cutting-edge\
    \ technology such as transformer based classification. Our chatbot, AVA, responds\
    \ to tens of thousands of customer interactions monthly, and we are evolving our\
    \ architecture to be supported by customer inference.\n\nWe will discuss our experience\
    \ of piloting transformer-based intent models, and present a workflow for going\
    \ from data to deployment for similar projects."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/A1.png
  section: A1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A1.png
  title: ' Rolling out Transformers with TorchScript and Inferentia'
- authors:
  - Kashif Rasul
  categories:
  - NLP & Multimodal, RL & Time Series
  description: PyTorchTS is a PyTorch based Probabilistic Time Series forecasting
    framework that comes with state of the art univariate and multivariate models.
  link: https://github.com/zalandoresearch/pytorch-ts
  poster_link: https://assets.pytorch.org/pted2021/posters/A2.png
  section: A2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A2.png
  title: 'PyTorchTS: PyTorch Probabilistic Time Series Forecasting Framework'
- authors:
  - Sasha Sheng
  - Amanpreet Singh
  categories:
  - NLP & Multimodal, RL & Time Series
  description: MMF is designed from ground up to let you focus on what matters --
    your model -- by providing boilerplate code for distributed training, common datasets
    and state-of-the-art pretrained baselines out-of-the-box. MMF is built on top
    of PyTorch that brings all of its power in your hands. MMF is not strongly opinionated.
    So you can use all of your PyTorch knowledge here. MMF is created to be easily
    extensible and composable. Through our modular design, you can use specific components
    from MMF that you care about. Our configuration system allows MMF to easily adapt
    to your needs.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/A3.png
  section: A3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A3.png
  title: 'MMF: A modular framework for multimodal research'
- authors:
  - Dirk Groeneveld
  - Akshita Bhagia
  - Pete Walsh
  - Michael Schmitz
  categories:
  - NLP & Multimodal, RL & Time Series
  description: An Apache 2.0 NLP research library, built on PyTorch, for developing
    state-of-the-art deep learning models on a wide variety of linguistic tasks.
  link: https://github.com/allenai/allennlp
  section: B1
  title: 'AllenNLP: An NLP research library for developing state-of-the-art models'
- authors:
  - John Trenkle
  - Jaya Kawale & Tubi ML team
  categories:
  - NLP & Multimodal, RL & Time Series
  description: "Tubi is one of the leading platforms providing free high-quality streaming\
    \ movies and TV shows to a worldwide audience. We embrace a data-driven approach\
    \ and leverage advanced machine learning techniques using PyTorch to enhance our\
    \ platform and business in any way we can.  The Three Pillars of AVOD are the\
    \ guiding principle for our work.  The Pillars are \nContent: all the titles we\
    \ maintain in our library\nAudience: everyone who watches titles on Tubi\nAdvertising:\
    \ ads shown to viewers on behalf of brands\n\nIn this poster, we'll focus on the\
    \ Content aspect with more details for the various use cases especially Content\
    \ Understanding. Content is an important pillar of Tubi since to be successful,\
    \ we need to look at existing titles and beyond what we already have and attempt\
    \ to understand all of the titles out in the wild and how they could benefit our\
    \ platform in some fashion. Content Understanding revolves around digesting a\
    \ rich collection of 1st- and 3rd-party data in structured (metadata) and unstructured\
    \ (text) forms and developing representations that capture the essence of those\
    \ Titles. With the analogy of linear algebra, we can say we are attempting to\
    \ project Title vectors from the universe to our tubiverse with as much fidelity\
    \ as possible in order to ascertain potential value for each target use case.\
    \ We will describe several techniques to understand content better using Pytorch."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/B2.png
  section: B2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-B2.png
  title: 'Project Spock at Tubi: Understanding Content using Deep Learning for NLP'
- authors:
  - Benoit Steiner
  - Chris Cummins
  - Horace He
  - Hugh Leather
  categories:
  - NLP & Multimodal, RL & Time Series
  description: "As the usage of machine learning techniques is becoming ubiquitous,\
    \ the efficient execution of neural networks is crucial to many applications.\
    \ Frameworks, such as Halide and TVM, separate the algorithmic representation\
    \ of\nthe deep learning model from the schedule that determines its implementation.\
    \ Finding good schedules, however, remains extremely challenging. Auto-tuning\
    \ methods, which search the space of valid schedules and execute each candidate\
    \ on the hardware, identify some of the best performing schedules, but the search\
    \ can take hours, hampering the productivity of deep learning practitioners. What\
    \ is needed is a method that achieves a similar performance without extensive\
    \ search, delivering the needed efficiency quickly.\n\nUsing PyTorch, we model\
    \ the scheduling process as a sequence of optimization choices, and implement\
    \ a new technique to accurately predict the expected performance of a partial\
    \ schedule using a LSTM over carefully engineered features that describe each\
    \ DNN operator and their current scheduling choices. Leveraging these predictions\
    \ we are able to make these optimization decisions greedily and, without any executions\
    \ on the target hardware, rapidly identify an efficient schedule.\nThis techniques\
    \ enables to find schedules that improve the execution performance of deep neural\
    \ networks by 2.6\xD7 over Halide and 1.5\xD7 over TVM. Moreover, our technique\
    \ completes in seconds instead of hours, making it  possible to include it as\
    \ a new backend for PyTorch itself."
  link: http://facebook.ai
  poster_link: https://assets.pytorch.org/pted2021/posters/B3.png
  section: B3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-B3.png
  title: RL Based Performance Optimization of Deep Neural Networks
- authors:
  - Zhenghong Liu
  categories:
  - NLP & Multimodal, RL & Time Series
  description: Forte is an open-source toolkit for building Natural Language Processing
    workflows via assembling state-of-the-art NLP and ML technologies. This toolkit
    features composable pipeline, cross-task interaction, adaptable data-model interfaces.
    The highly composable design allows users to build complex NLP pipelines of a
    wide range of tasks including document retrieval, information extraction, and
    text generation by combining existing toolkits or customized PyTorch models. The
    cross-task interaction ability allows developers to utilize the results from individual
    tasks to make informed decisions. The data-model interface helps developers to
    focus on building reusable PyTorch models by abstracting out domain and preprocessing
    details. We show that Forte can be used to build complex pipelines, and the resulting
    pipeline can be easily adapted to different domains and tasks with small changes
    in the code.
  link: https://github.com/asyml/forte
  poster_link: https://assets.pytorch.org/pted2021/posters/C1.png
  section: C1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C1.png
  title: A Data-Centric Framework for Composable NLP
- authors:
  - Shagun Sodhani
  - Amy Zhang
  - Ludovic Denoyer
  - Pierre-Alexandre Kamienny
  - Olivier Delalleau
  categories:
  - NLP & Multimodal, RL & Time Series
  description: 'The two key components in a multi-task RL codebase are (i) Multi-task
    RL algorithms and (ii) Multi-task RL environments. We develop open-source libraries
    for both components. [MTRL](https://github.com/facebookresearch/mtrl) provides
    components to implement multi-task RL algorithms, and [MTEnv](https://github.com/facebookresearch/mtenv)
    is a library to interface with existing multi-task RL environments and create
    new ones.


    MTRL has two building blocks: (i) single task policy and (ii) components to augment
    the single-task policy for multi-task setup. The ideal workflow is to start with
    a base policy and add multi-task components as they seem fit. MTRL enables algorithms
    like GradNorm, Distral, HiPBMDP, PCGrad, Soft Modularization, etc.


    MTEnv is an effort to standardize multi-task RL environments and provide better
    benchmarks. We extend the Gym API to support multiple tasks, with two guiding
    principles: (i) Make minimal changes to the Gym Interface (which the community
    is very familiar with) and (ii) Make it easy to port existing environments to
    MTEnv. Additionally, we provide a collection of commonly used multi-task RL environments
    (Acrobot, Cartpole, Multitask variant of DeepMind Control Suite, Meta-World, Multi-armed
    Bandit, etc.). The RL practitioner can combine its own environments with the MTEnv
    wrappers to add multi-task support with a small code change.


    MTRL and MTEnv are used in several ongoing/published works at FAIR.'
  link: http://qr.w69b.com/g/tGZSFw33G
  poster_link: https://assets.pytorch.org/pted2021/posters/C2.png
  section: C2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C2.png
  title: Environments and Baselines for Multitask Reinforcement Learning
- authors:
  - Lysandre Debut
  - Sylvain Gugger
  - "Quentin Lhoest\_"
  categories:
  - NLP & Multimodal, RL & Time Series
  description: 'Transfer learning has become the norm to get state-of-the-art results
    in NLP. Hugging Face provides you with tools to help you on every step along the
    way:


    - A free git-based shared hub with more than 7,500 PyTorch checkpoints, and more
    than 800 NLP datasets.

    - The ? Datasets library, to easily download the dataset, manipulate it and prepare
    it.

    - The ? Tokenizers library, that provides ultra-fast tokenizers backed by Rust,
    and converts text in PyTorch tensors.

    - The ? Transformers library, providing more than 45 PyTorch implementations of
    Transformer architectures as simple nn.Module as well as a training API.

    - The ? Accelerate library, a non-intrusive API that allows you to run your raw
    training loop on any distributed setup.


    The pipeline is then simply a six-step process: select a pretrained model from
    the hub, handle the data with Datasets, tokenize the text with Tokenizers, load
    the model with Transformers, train it with the Trainer or your own loop powered
    by Accelerate, before sharing your results with the community on the hub.'
  link: https://huggingface.co/models
  poster_link: https://assets.pytorch.org/pted2021/posters/C3.png
  section: C3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C3.png
  title: The Hugging Face Ecosystem
- authors:
  - Manuel Pariente
  - Samuele Cornell
  - Jonas Haag
  - Joris Cosentino
  - Michel Olvera
  - "Fabian-Robert St\xF6ter"
  - Efthymios Tzinis
  categories:
  - NLP & Multimodal, RL & Time Series
  description: Asteroid is an audio source separation toolkit built with PyTorch and
    PyTorch-Lightning. Inspired by the most successful neural source separation systems,
    it provides all neural building blocks required to build such a system. To improve
    reproducibility, recipes on common audio source separation datasets are provided,
    including all the steps from data download\preparation through training to evaluation
    as well as many current state-of-the-art DNN models. Asteroid exposes all levels
    of granularity to the user from simple layers to complete ready-to-use models.
    Our pretrained models are hosted on the asteroid-models community in Zenodo and
    on the Huggingface model Hub. Loading and using pretrained models is trivial and
    sharing them is also made easy with asteroid's CLI.","poster_showcase":"Audio
    Source Separation, Speech Processing, Deep Learning","email":"cornellsamuele@gmail.com"}
  link: https://asteroid-team.github.io/
  poster_link: https://assets.pytorch.org/pted2021/posters/D1.png
  section: D1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D1.png
  title: "\_Asteroid: the Pytorch-based Audio Source Separation Toolkit for Researchers"
- authors:
  - Ludovic Denoyer
  - Danielle Rothermel
  - Xavier Martinet
  categories:
  - NLP & Multimodal, RL & Time Series
  description: RLStructures is a lightweight Python library that provides simple APIs
    as well as data structures that make as few assumptions as possible about the
    structure of your agent or your task, while allowing for transparently executing
    multiple policies on multiple environments in parallel (incl. multiple GPUs).
    It thus facilitates the implementation of RL algorithms while avoiding complex
    abstractions.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/D2.png
  section: D2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D2.png
  title: 'rlstructures: A Lightweight Python Library for Reinforcement Learning Research'
- authors:
  - Luis Pineda
  - Brandon Amos
  - Amy Zhang
  - Nathan O. Lambert
  - Roberto Calandra
  categories:
  - NLP & Multimodal, RL & Time Series
  description: Model-based reinforcement learning (MBRL) is an active area of research
    with enormous potential. In contrast to model-free RL, MBRL algorithms solve tasks
    by learning a predictive model of the task dynamics, and use this model to predict
    the future and facilitate decision making. Many researchers have argued that MBRL
    can result in lower sample complexity, better generalization, as well as safer
    and more interpretable decisions. However, despite the surge in popularity and
    great potential of MBRL, there is currently no widely accepted library for facilitating
    research in this area. Since MBRL methods often involve the interplay of complex
    components such as probabilistic ensembles, latent variable models, planning algorithms,
    and even model-free methods, the lack of such a library raises the entry bar to
    the field and slows down research efforts. In this work we aim to solve this problem
    by introducing MBRL-Lib, a modular PyTorch toolbox specifically designed for facilitating
    research on model-based reinforcement learning. MBRL-Lib provides interchangeable
    options for training dynamics models and running planning algorithms, which can
    then be used in a mix and match fashion to create novel MBRL methods. The library
    also provides a set of utility functions to run common MBRL tasks, as well a set
    of diagnostics tools to identify potential issues while training dynamics models
    and control algorithms.
  link: https://github.com/facebookresearch/mbrl-lib
  poster_link: https://assets.pytorch.org/pted2021/posters/D3.png
  section: D3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D3.png
  title: 'MBRL-Lib: a PyTorch toolbox for model-based reinforcement learning research'
- authors:
  - Geeta Chauhan
  - Gisle Dankel
  - Elena Neroslavaskaya
  categories:
  - Performance & Profiler
  description: Analyzing and improving large-scale deep learning model performance
    is an ongoing challenge that continues to grow in importance as the model sizes
    increase. Microsoft and Facebook collaborated to create a native PyTorch performance
    debugging tool called PyTorch Profiler. The profiler builds on the PyTorch autograd
    profiler foundation, adds a new high fidelity GPU profiling engine, and out-of-the-box
    bottleneck analysis tool in Tensorboard. New Profiler delivers the simplest experience
    available to date where users can profile their models without installing any
    additional packages and see results immediately in Tensorboard. Until today, beginner
    users of PyTorch may not have attempted to profile their models due to the task
    complexity. With the new bottleneck analysis tool, they will find profiling easy
    and accessible. Experienced users will be delighted by the detailed trace views
    which illustrate GPU kernel execution events and their relationship to the PyTorch
    operations. Come learn how to profile your PyTorch models using this new delightfully
    simple tool.
  link: https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool
  poster_link: https://assets.pytorch.org/pted2021/posters/H6.png
  section: H6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H6.png
  title: Introducing New PyTorch Profiler
- authors:
  - Naren Dasan
  categories:
  - Performance & Profiler
  description: For experimentation and the development of machine learning models,
    few tools are as approachable as PyTorch. However, when moving from research to
    production, some of the features that make PyTorch great for development make
    it hard to deploy. With the introduction of TorchScript, PyTorch has solid tooling
    for addressing some of the problems of deploying PyTorch models. TorchScript removes
    the dependency on Python and produces portable, self contained, static representations
    of code and weights. But in addition to portability, users also look to optimize
    performance in deployment. When deploying on NVIDIA GPUs, TensorRT, NVIDIA's deep
    learning optimizer, provides the capability to maximize performance of workloads
    by tuning the execution of models for specific target hardware. TensorRT also
    provides tooling for conducting further optimization through mixed and reduced
    precision execution and post training quantization (PTQ). We present TRTorch,
    a compiler for PyTorch and TorchScript targeting NVIDIA GPUs, which combines the
    usability of PyTorch with the performance of TensorRT and allows users to fully
    optimize their inference workloads without leaving the PyTorch ecosystem. It also
    simplifies conducting complex optimizations like PTQ by leveraging common PyTorch
    tooling. TRTorch can be used directly from PyTorch as a TorchScript Backend, embedded
    in an application or used from the command line to easily increase the performance
    of inference applications.
  link: https://nvidia.github.io/TRTorch/
  poster_link: https://assets.pytorch.org/pted2021/posters/I6.png
  section: I6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I6.png
  title: 'TRTorch: A Compiler for TorchScript Targeting NVIDIA GPUs with TensorRT'
- authors:
  - Charles H. Martin
  categories:
  - Performance & Profiler
  description: "WeightWatcher (WW) is an open-source, diagnostic tool for analyzing\
    \ Deep Neural Networks (DNN), without needing access to training or even test\
    \ data. It can be used to: analyze pre/trained pyTorch models; \ninspect models\
    \ that are difficult to train; gauge improvements in model performance; predict\
    \ test accuracies across different models; and detect potential problems when\
    \ compressing or fine-tuning pretrained models.\n\nWeightWatcher is based on theoretical\
    \ research (done in\\-joint with UC Berkeley) into \"Why Deep Learning Works\"\
    , using ideas from Random Matrix Theory (RMT), Statistical Mechanics, and Strongly\
    \ Correlated Systems."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/J6.png
  section: J6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J6.png
  title: 'WeightWatcher: A Diagnostic Tool for DNNs'
- authors:
  - Mario Lezcano-Casado
  categories:
  - Performance & Profiler
  description: '"This poster presents the ""parametrizations"" feature that will be
    added to PyTorch in 1.9.0.

    This feature allows for a simple implementation of methods like pruning, weight_normalization
    or spectral_normalization.

    More generally, it implements a way to have ""computed parameters"". This means
    that we replace a parameter `weight` in a layer with `f(weight)`, where `f` is
    an arbitrary module. In other words, after putting a parametrization `f` on `layer.weight`,
    `layer.weight` will return `f(weight)`.

    They implement a caching system, so that the value `f(weight)` is computed just
    once during the forward pass.

    A module that implements a parametrisation may also have a `right_inverse` method.
    If this method is present, it is possible to assign to a parametrised tensor.
    This is useful when initialising a parametrised tensor.

    This feature can be seen as a first step towards invertible modules. In particular,
    it may also help making distributions first-class citizens in PyTorch.

    Parametrisations also allows for a simple implementation of constrained optimisation.
    From this perspective, parametrisation maps an unconstrained tensor to a constrained
    space such as the space of orthogonal matrices, SPD matrices, low-rank matrices...
    This approach is implemented in the library GeoTorch (https://github.com/Lezcano/geotorch/)."'
  link: ''
  section: K6
  title: Constrained Optimization in PyTorch 1.9 Through Parametrizations
- authors:
  - Richard Liaw
  - Kai Fricke
  - Amog Kamsetty
  - Michael Galarnyk
  categories:
  - Platforms & Ops & Tools
  description: Ray is a popular framework for distributed Python that can be paired
    with PyTorch to rapidly scale machine learning applications. Ray contains a large
    ecosystem of applications and libraries that leverage and integrate with Pytorch.
    This includes Ray Tune, a Python library for experiment execution and hyperparameter
    tuning at any scale; RLlib, a state-of-the-art library for reinforcement learning;
    and Ray Serve, a library for scalable model serving. Together, Ray and Pytorch
    are becoming the core foundation for the next generation of production machine
    learning platforms.
  link: https://ray.io/
  poster_link: https://assets.pytorch.org/pted2021/posters/H1.png
  section: H1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H1.png
  title: Distributed Pytorch with Ray
- authors:
  - Vincenzo Lomonaco
  - Lorenzo Pellegrini Andrea Cossu
  - Antonio Carta
  - Gabriele Graffieti
  categories:
  - Platforms & Ops & Tools
  description: Learning continually from non-stationary data stream is a long sought
    goal of machine learning research. Recently, we have witnessed a renewed and fast-growing
    interest in Continual Learning, especially within the deep learning community.
    However, algorithmic solutions are often difficult to re-implement, evaluate and
    port across different settings, where even results on standard benchmarks are
    hard to reproduce. In this work, we propose an open-source, end-to-end library
    for continual learning based on PyTorch that may provide a shared and collaborative
    code-base for fast prototyping, training and reproducible evaluation of continual
    learning algorithms.
  link: https://avalanche.continualai.org
  poster_link: https://assets.pytorch.org/pted2021/posters/H2.png
  section: H2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H2.png
  title: 'Avalanche: an End-to-End Library for Continual Learning based on PyTorch'
- authors:
  - Hong Xu
  categories:
  - Platforms & Ops & Tools
  description: IBM Z is a hardware product line for mission-critical applications,
    such as finance and health applications. It employs its own CPU architecture,
    which PyTorch does not officially support. In this poster, we discuss why it is
    important to support PyTorch on Z. Then, we show our prebuilt minimal PyTorch
    package for IBM Z. Finally, we demonstrate our continuing commitment to make more
    PyTorch features available on IBM Z.
  link: https://codait.github.io/pytorch-on-z
  poster_link: https://assets.pytorch.org/pted2021/posters/H3.png
  section: H3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-H3.png
  title: PyTorch on IBM Z and LinuxONE (s390x)
- authors:
  - Dr. Ariel Biller
  categories:
  - Platforms & Ops & Tools
  description: "Both from sanity considerations and the productivity perspective,\
    \ Data Scientists, ML engineers, Graduate students, and other research-facing\
    \ roles are all starting to adopt best-practices from production-grade MLOps.\n\
    \nHowever, most toolchains come with a hefty price of extra code and maintenance,\
    \ which reduces the actual time available for R&D. We will show an alternative\
    \ approach using ClearML, the open-source MLOps solution.\n\nIn this \"best-practices\"\
    \ poster, we will overview the \"must-haves\" of R&D-MLOPs: \nOrchestration, Automation,\
    \ and Reproducibility. These enable easy remote execution through magically reproducible\
    \ setups and even custom, reusable, bottom-up pipelines.\n\nWe will take a single\
    \ example and schematically transform it from the \"as downloaded from GitHub\"\
    \ stage to a fully-fledged, scalable, version-controlled, parameterizable R&D\
    \ pipeline. We will measure the number of changes needed to the codebase and provide\
    \ evidence of real low-cost integration. All code, logs, and metrics will be available\
    \ as supporting information."
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/I1.png
  section: I1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I1.png
  title: 'The Fundamentals of MLOps for R&D: Orchestration, Automation, Reproducibility'
- authors:
  - Masashi Sode
  - Akihiko Fukuchi
  - Yoki Yabe
  - Yasufumi Nakata
  categories:
  - Platforms & Ops & Tools
  description: "Is your machine learning model fair enough to be used in your system?\
    \ What if a recruiting AI discriminates on gender and race? What if the accuracy\
    \ of medical AI depends on a person's annual income or on the GDP of the country\
    \ where it is used? Today's AI has the potential to cause such problems. In recent\
    \ years, fairness in machine learning has received increasing attention. If current\
    \ machine learning models used for decision making may cause unfair discrimination,\
    \ developing a fair machine learning model is an important goal in many areas,\
    \ such as medicine, employment, and politics. Despite the importance of this goal\
    \ to society, as of 2020, there was no PyTorch\xB9 project incorporating fairness\
    \ into a machine learning model. To solve this problem, we created FairTorch at\
    \ the PyTorch Summer Hackathon 2020.\n\nFairTorch provides a tool to mitigate\
    \ the unfairness of machine learning models. A unique feature of our tool is that\
    \ it allows you to add a fairness constraint to your model by adding only a few\
    \ lines of code, using the fairness criteria provided in the library."
  link: https://github.com/wbawakate/fairtorch
  poster_link: https://assets.pytorch.org/pted2021/posters/I2.png
  section: I2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I2.png
  title: 'FairTorch: Aspiring to Mitigate the Unfairness of Machine Learning Models'
- authors:
  - Thomas Viehmann
  - Luca Antiga
  categories:
  - Platforms & Ops & Tools
  description: 'When machine learning models are deployed to solve a given task, a
    crucial question is whether they are actually able to perform as expected. TorchDrift
    addresses one aspect of the answer, namely drift detection, or whether the information
    flowing through our models - either probed at the input, output or somewhere in-between
    - is still consistent with the one it was trained and evaluated on. In a nutshell,
    TorchDrift is designed to be plugged into PyTorch models and check whether they
    are operating within spec.

    TorchDrift''s principles apply PyTorch''s motto _from research to production_
    to drift detection: We provide a library of methods that canbe used as baselines
    or building blocks for drift detection research, as well as provide practitioners
    deploying PyTorch models in production with up-to-date methods and educational
    material for building the necessary statistical background. Here we introduce
    TorchDrift with an example illustrating the underlying two-sample tests. We show
    how TorchDrift can be integrated in high-performance runtimes such as TorchServe
    or RedisAI, to enable drift detection in real-world applications thanks to the
    PyTorch JIT.'
  link: https://torchdrift.org/
  poster_link: https://assets.pytorch.org/pted2021/posters/I3.png
  section: I3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-I3.png
  title: 'TorchDrift: Drift Detection for PyTorch'
- authors:
  - Quincy Chen
  - Arjun Bhargava
  - Sudeep Pillai
  - Marcus Pan
  - Chao Fang
  - Chris   Ochoa
  - Adrien Gaidon
  - Kuan-Hui Lee
  - Wolfram Burgard
  categories:
  - Platforms & Ops & Tools
  description: "Modern machine learning for autonomous vehicles requires a fundamentally\
    \ different infrastructure and production lifecycle from their standard software\
    \ continuous-integration/continuous-deployment counterparts. At Toyota Research\
    \ Institute (TRI), we have developed \u200BOuroboros\u200B - a modern ML platform\
    \ that supports the end-to-end lifecycle of all ML models delivered to TRI's autonomous\
    \ vehicle fleets. We envision that all ML models delivered to our fleet undergo\
    \ a systematic and rigorous treatment. Ouroboros delivers several essential features\
    \ including:\na. ML dataset governance and infrastructure-as-code\u200B that ensures\
    \ the traceability, reproducibility, standardization, and fairness for all ML\
    \ datasets and models procedurally generated and delivered to the TRI fleet.\n\
    b. Unified ML dataset and model management:\u200B An unified and streamlined workflow\
    \ for ML dataset curation, label management, and model development that supports\
    \ several key ML models delivered to the TRI fleet today\nc. A Large-scale Multi-task,\
    \ Multi-modal Dataset for Automated Driving\u200B that supports the development\
    \ of various models today, including 3D object detection, 2D object detection,\
    \ 2D BeVFlow, Panoptic Segmentation;\nd. Orchestrated ML workflows\u200B to stand\
    \ up scalable ML applications such as push-button re-training solutions, ML CI/CDs\
    \ pipelines, Dataset Curation workflows, Auto-labelling pipelines, leveraging\
    \ the most up-to-date cloud tools available. along their lifecycles, ensuring\
    \ strong governance on building reusable, reproducible, robust, traceable, and\
    \ fair ML models for the production driving setting. By following the best MLOps\
    \ practices, we expect our platform to lay the foundation for continuous life-long\
    \ learning in our autonomous vehicle fleets and accelerate the transition from\
    \ research to production."
  link: https://github.com/TRI-ML
  poster_link: https://assets.pytorch.org/pted2021/posters/J1.png
  section: J1
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J1.png
  title: 'Ouroboros: MLOps for Automated Driving'
- authors:
  - Yujian He
  categories:
  - Platforms & Ops & Tools
  description: carefree-learn makes PyTorch accessible to people who are familiar
    with machine learning but not necessarily PyTorch. By having already implemented
    all the pre-processing and post-processing under the hood, users can focus on
    implementing the core machine learning algorithms / models with PyTorch and test
    them on various datasets. By having designed the whole structure carefully, users
    can easily customize every block in the whole pipeline, and can also 'combine'
    the implemented blocks to 'construct' new models without efforts. By having carefully
    made abstractions users can adapt it to their specific down-stream tasks, such
    as quantitative trading (in fact I've already implemented one for my company and
    it works pretty well XD). carefree-learn handles distributed training carefully,
    so users can either run multiple tasks at the same time, or run a huge model with
    DDP in one line of code. carefree-learn also integrates with mlflow and supports
    exporting to ONNX, which means it is ready for production to some extend.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/J2.png
  section: J2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J2.png
  title: "carefree-learn: Tabular Datasets \u2764\uFE0F PyTorch"
- authors:
  - Wenwei Zhang
  categories:
  - Platforms & Ops & Tools
  description: 'OpenMMLab project builds open-source toolboxes for Artificial Intelligence
    (AI). It aims to 1) provide high-quality codebases to reduce the difficulties
    in algorithm reimplementation; 2) provide a complete research platform to accelerate
    the research production; and 3) shorten the gap between research production to
    the industrial applications. Based on PyTorch, OpenMMLab develops MMCV to provide
    unified abstract training APIs and common utils, which serves as a foundation
    of 15+ toolboxes and 40+ datasets.


    Since the initial release in October 2018, OpenMMLab has released 15+ toolboxes
    that cover 10+ directions, implement 100+ algorithms, and contain 1000+ pre-trained
    models. With a tighter collaboration with the community, OpenMMLab will release
    more toolboxes with more flexible and easy-to-use training frameworks in the future.'
  link: https://openmmlab.com/
  poster_link: https://assets.pytorch.org/pted2021/posters/J3.png
  section: J3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-J3.png
  title: 'OpenMMLab: An Open-Source Algorithm Platform for Computer Vision'
- authors:
  - Sergey Kolesnikov
  categories:
  - Platforms & Ops & Tools
  description: "For the last three years, Catalyst-Team and collaborators have been\
    \ working on Catalyst\u200A -  a high-level PyTorch framework Deep Learning Research\
    \ and Development. It focuses on reproducibility, rapid experimentation, and codebase\
    \ reuse so you can create something new rather than write yet another train loop.\
    \ You get metrics, model checkpointing, advanced logging, and distributed training\
    \ support without the boilerplate and low-level bugs."
  link: https://catalyst-team.com
  poster_link: https://assets.pytorch.org/pted2021/posters/K2.png
  section: K2
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K2.png
  title: "Catalyst \u2013 Accelerated deep learning R&D"
- authors:
  - Anton Obukhov
  categories:
  - Platforms & Ops & Tools
  description: "Evaluation of generative models such as GANs is an important part\
    \ of deep learning research. In 2D image generation, three approaches became widely\
    \ spread: Inception Score, Fr\xE9chet Inception Distance, and Kernel Inception\
    \ Distance. Despite having a clear mathematical and algorithmic description, these\
    \ metrics were initially implemented in TensorFlow and inherited a few properties\
    \ of the framework itself, such as a specific implementation of the interpolation\
    \ function. These design decisions were effectively baked into the evaluation\
    \ protocol and became an inherent part of the specification of the metrics. As\
    \ a result, researchers wishing to compare against state of the art in generative\
    \ modeling are forced to perform an evaluation using the original metric authors'\
    \ codebases. Reimplementations of metrics in PyTorch and other frameworks exist,\
    \ but they do not provide a proper level of fidelity, thus making them unsuitable\
    \ for reporting results and comparing them to other methods. This software aims\
    \ to provide epsilon-exact implementations of the said metrics in PyTorch and\
    \ remove inconveniences associated with generative model evaluation and development.\
    \ All the evaluation pipeline steps are correctly tested, with relative errors\
    \ and sources of remaining non-determinism summarized in sections below.\nTLDR;\
    \ fast and reliable GAN evaluation in PyTorch"
  link: https://github.com/toshas/torch-fidelity
  poster_link: https://assets.pytorch.org/pted2021/posters/K3.png
  section: K3
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-K3.png
  title: High-fidelity performance metrics for generative models in PyTorch
- authors:
  - 'Jona Raphael (jona@skytruth.org)'
  - Ben Eggleston
  - Ryan Covington
  - Tatianna Evanisko
  - John Amos
  categories:
  - Vision
  description: "Operational oil discharges from ships, also known as \"bilge dumping,\"\
    \ have been identified as a major source of petroleum products entering our oceans,\
    \ cumulatively exceeding the largest oil spills, such as the Exxon Valdez and\
    \ Deepwater Horizon spills, even when considered over short time spans. However,\
    \ we still don't have a good estimate of\n\u25CF How much oil is being discharged;\n\
    \u25CF Where the discharge is happening;\n\u25CF Who the responsible vessels are.\n\
    This makes it difficult to prevent and effectively respond to oil pollution that\
    \ can damage our marine and coastal environments and economies that depend on\
    \ them.\n\nIn this poster we will share SkyTruth's recent work to address these\
    \ gaps using machine learning tools to detect oil pollution events and identify\
    \ the responsible vessels when possible. We use a convolutional neural network\
    \ (CNN) in a ResNet-34 architecture to perform pixel segmentation on all incoming\
    \ Sentinel-1 synthetic aperture radar (SAR) imagery to classify slicks. Despite\
    \ the satellites' incomplete oceanic coverage, we have been detecting an average\
    \ of 135 vessel slicks per month, and have identified several geographic hotspots\
    \ where oily discharges are occurring regularly. For the images that capture a\
    \ vessel in the act of discharging oil, we rely on an Automatic Identification\
    \ System (AIS) database to extract details about the ships, including vessel type\
    \ and flag state. We will share our experience\n\u25CF Making sufficient training\
    \ data from inherently sparse satellite image datasets;\n\u25CF Building a computer\
    \ vision model using PyTorch and fastai;\n\u25CF Fully automating the process\
    \ in the Amazon Web Services (AWS) cloud.\nThe application has been running continuously\
    \ since August 2020, has processed over 380,000 Sentinel-1 images, and has populated\
    \ a database with more than 1100 high-confidence slicks from vessels. We will\
    \ be discussing preliminary results from this dataset and remaining challenges\
    \ to be overcome.\nLearn more at https://skytruth.org/bilge-dumping/"
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/A6.png
  section: A6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A6.png
  title: Using Satellite Imagery to Identify Oceanic Oil Pollution
- authors:
  - Tanishq Abraham
  categories:
  - Vision
  description: Unpaired image-to-image translation algorithms have been used for various
    computer vision tasks like style transfer and domain adaption. Such algorithms
    are highly attractive because they alleviate the need for the collection of paired
    datasets. In this poster, we demonstrate UPIT, a novel fastai/PyTorch package
    (built with nbdev) for unpaired image-to-image translation. It implements various
    state-of-the-art unpaired image-to-image translation algorithms such as CycleGAN,
    DualGAN, UNIT, and more. It enables simple training and inference on unpaired
    datasets. It also comes with implementations of commonly used metrics like FID,
    KID, and LPIPS. It also comes with Weights-and-Biases integration for easy experiment
    tracking. Since it is built on top of fastai and PyTorch, it comes with support
    for mixed-precision and multi-GPU training. It is highly flexible, and custom
    dataset types, models, and metrics can be used as well. With UPIT, training and
    applying unpaired image-to-image translation only takes a few lines of code.
  link: https://github.com/tmabraham/UPIT
  poster_link: https://assets.pytorch.org/pted2021/posters/A7.png
  section: A7
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A7.png
  title: 'UPIT: A fastai Package for Unpaired Image-to-Image Translation'
- authors:
  - Aaron Adcock
  - Bo Xiong
  - Christoph Feichtenhofer
  - Haoqi Fan
  - Heng Wang
  - Kalyan Vasudev Alwala
  - Matt Feiszli
  - Tullie Murrell
  - Wan-Yen Lo
  - Yanghao Li
  - Yilei Li
  - 'Zhicheng Yan '
  categories:
  - Vision
  description: PyTorchVideo is the new Facebook AI deep learning library for video
    understanding research. It contains variety of state of the art pretrained video
    models, dataset, augmentation, tools for video understanding. PyTorchVideo provides
    efficient video components on accelerated inference on mobile device.
  link: https://pytorchvideo.org/
  poster_link: https://assets.pytorch.org/pted2021/posters/A8.png
  section: A8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-A8.png
  title: 'PyTorchVideo: A Deep Learning Library for Video Understanding'
- authors:
  - A. Speiser
  - "L-R. M\xFCller"
  - P. Hoess
  - U. Matti
  - C. J. Obara
  - J. H. Macke
  - J. Ries
  - S. C. Turaga
  categories:
  - Vision
  description: Single-molecule localization microscopy (SMLM) has had remarkable success
    in imaging cellular structures with nanometer resolution, but the need for activating
    only single isolated emitters limits imaging speed and labeling density. Here,
    we overcome this major limitation using deep learning. We developed DECODE, a
    computational tool that can localize single emitters at high density in 3D with
    the highest accuracy for a large range of imaging modalities and conditions. In
    a public software benchmark competition, it outperformed all other fitters on
    12 out of 12 data-sets when comparing both detection accuracy and localization
    error, often by a substantial margin. DECODE allowed us to take live-cell SMLM
    data with reduced light exposure in just 3 seconds and to image microtubules at
    ultra-high labeling density. Packaged for simple installation and use, DECODE
    will enable many labs to reduce imaging times and increase localization density
    in SMLM.
  link: http://github.com/turagalab/decode
  section: B6
  title: Deep Learning Enables Fast and Dense Single-Molecule Localization with High
    Accuracy
- authors:
  - "Abraham S\xE1nchez"
  - Guillermo Mendoza
  - "E. Ulises Moya-S\xE1nchez"
  categories:
  - Vision
  description: 'We draw inspiration from the cortical area V1. We try to mimic their
    main processing properties by means of: quaternion local phase/orientation to
    compute lines and edges detection in a specific direction. We analyze how this
    layer is robust by its greometry to large illumination and brightness changes.'
  link: https://gitlab.com/ab.sanchezperez/pytorch-monogenic
  poster_link: https://assets.pytorch.org/pted2021/posters/B7.png
  section: B7
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-B7.png
  title: A Robust PyTorch Trainable Entry Convnet Layer in Fourier Domain
- authors:
  - "Fran\xE7ois-Guillaume Fernandez"
  - Mateo Lostanlen
  - Sebastien Elmaleh
  - Bruno Lenzi
  - Felix Veith
  - and more than 15+ contributors
  categories:
  - Vision
  description: '"PyroNear is non-profit organization composed solely of volunteers
    which was created in late 2019. Our core belief is that recent technological developments
    can support the cohabitation between mankind & its natural habitat. We strive
    towards high-performing, accessible & affordable tech-solutions for protection
    against natural hazards. More specifically, our first efforts are focused on wildfire
    protection by increasing the coverage of automatic detection systems.


    Our ongoing initiative has now gathered dozens of volunteers to put up the following
    main contributions:

    - Computer Vision: compiling open-source models and datasets (soon to be published)
    for vision tasks related to wildfire detection

    - Edge Computing: developing an affordable physical prototype running our PyTorch
    model on a Raspberry Pi

    - End-to-end detection workflow: building a responsible end-to-end system for
    large scale detection and alert management (API, front-end monitoring platform)

    - Deployment: working with French firefighter departments to gather field knowledge
    and conduct a test phase over the incoming European summer."

    PyTorch3D is a modular and optimized library for 3D Deep Learning with PyTorch.
    It includes support for: data structures for heterogeneous batching of 3D data
    (Meshes, Point clouds and Volumes), optimized 3D operators and loss functions
    (with custom CUDA kernels), a modular differentiable rendering API for Meshes,
    Point clouds and Implicit functions, as well as several other tools for 3D Deep
    Learning.'
  link: https://github.com/pyronear
  poster_link: https://assets.pytorch.org/pted2021/posters/B8.png
  section: B8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-B8.png
  title: 'PyroNear: Embedded Deep Learning for Early Wildfire Detection'
- authors:
  - Nikhila Ravi
  - Jeremy Reizenstein
  - David Novotny
  - Justin Johnson
  - Georgia Gkioxari
  - Roman Shapovalov
  - Patrick Labatut
  - Wan-Yen Lo
  categories:
  - Vision
  description: 'PyTorch3D is a modular and optimized library for 3D Deep Learning
    with PyTorch. It includes support for: data structures for heterogeneous batching
    of 3D data (Meshes, Point clouds and Volumes), optimized 3D operators and loss
    functions (with custom CUDA kernels), a modular differentiable rendering API for
    Meshes, Point clouds and Implicit functions, as well as several other tools for
    3D Deep Learning.'
  link: https://arxiv.org/abs/2007.08501
  poster_link: https://assets.pytorch.org/pted2021/posters/C6.png
  section: C6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C6.png
  title: 'PyTorch3D: Fast, Flexible, 3D Deep Learning  '
- authors:
  - E. Riba
  - J. Shi
  - D. Mishkin
  - L. Ferraz
  - A. Nicolao
  categories:
  - Vision
  description: This work presents Kornia, an open source computer vision library built
    upon a set of differentiable routines and modules that aims to solve generic computer
    vision problems. The package uses PyTorch as its main backend, not only for efficiency
    but also to take advantage of the reverse auto-differentiation engine to define
    and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed
    of a set of modules containing operators that can be integrated into neural networks
    to train models to perform a wide range of operations including image transformations,camera
    calibration, epipolar geometry, and low level image processing techniques, such
    as filtering and edge detection that operate directly on high dimensional tensor
    representations on graphical processing units, generating faster systems. Examples
    of classical vision problems implemented using our framework are provided including
    a benchmark comparing to existing vision libraries.
  link: http://www.kornia.org
  poster_link: https://assets.pytorch.org/pted2021/posters/C7.png
  section: C7
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C7.png
  title: 'Kornia: an Open Source Differentiable Computer Vision Library for PyTorch'
- authors:
  - Thomas George
  categories:
  - Vision
  description: Fisher Information Matrices (FIM) and Neural Tangent Kernels (NTK)
    are useful tools in a number of diverse applications related to neural networks.
    Yet these theoretical tools are often difficult to implement using current libraries
    for practical size networks, given that they require per-example gradients, and
    a large amount of memory since they scale as the number of parameters (for the
    FIM) or the number of examples x cardinality of the output space (for the NTK).
    NNGeometry is a PyTorch library that offers a high level API for computing various
    linear algebra operations such as matrix-vector products, trace, frobenius norm,
    and so on, where the matrix is either the FIM or the NTK, leveraging recent advances
    in approximating these matrices.
  link: https://github.com/tfjgeorge/nngeometry/
  poster_link: https://assets.pytorch.org/pted2021/posters/C8.png
  section: C8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-C8.png
  title: 'NNGeometry: Easy and Fast Fisher Information Matrices and Neural Tangent
    Kernels in PyTorch'
- authors:
  - "B\xE9gaint J."
  - "Racap\xE9 F."
  - Feltman S.
  - Pushparaja A.
  categories:
  - Vision
  description: CompressAI is a PyTorch library that provides custom operations, layers,
    modules and tools to research, develop and evaluate end-to-end image and video
    compression codecs. In particular, CompressAI includes pre-trained models and
    evaluation tools to compare learned methods with traditional codecs. State-of-the-art
    end-to-end compression models have been reimplemented in PyTorch and trained from
    scratch, reproducing published results and allowing further research in the domain.
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/D6.png
  section: D6
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D6.png
  title: 'CompressAI: a research library and evaluation platform for end-to-end compression  '
- authors:
  - Philip Meier
  - Volker Lohweg
  categories:
  - Vision
  description: "The seminal work of Gatys, Ecker, and Bethge gave birth to the field\
    \ of _Neural Style Transfer_ (NST) in 2016. An NST describes the merger between\
    \ the content and artistic style of two arbitrary images. This idea is nothing\
    \ new in the field of Non-photorealistic rendering (NPR). What distinguishes NST\
    \ from traditional NPR approaches is its generality: an NST only needs a single\
    \ arbitrary content and style image as input and thus \"makes -- for the first\
    \ time -- a generalized style transfer practicable\". Besides peripheral tasks,\
    \ an NST at its core is the definition of an optimization criterion called _perceptual\
    \ loss_, which estimates the perceptual quality of the stylized image. Usually\
    \ the perceptual loss comprises a deep neural network that needs to supply encodings\
    \ of images from various depths. \n\n`pystiche` is a library for NST written in\
    \ Python and built upon PyTorch. It provides modular and efficient implementations\
    \ for commonly used perceptual losses as well as neural net architectures. This\
    \ enables users to mix current state-of-the-art techniques with new ideas with\
    \ ease. This poster will showcase the core concepts of `pystiche` that will enable\
    \ other researchers as well as lay persons to got an NST running in minutes."
  link: https://github.com/pmeier/pystiche
  poster_link: https://assets.pytorch.org/pted2021/posters/D7.png
  section: D7
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D7.png
  title: 'pystiche: A Framework for Neural Style Transfer'
- authors:
  - Siddhish Thakur
  categories:
  - Vision
  description: ' Deep Learning (DL) has greatly highlighted the potential impact of
    optimized machine learning in both the scientific

    and clinical communities. The advent of open-source DL libraries from major industrial
    entities, such as TensorFlow

    (Google), PyTorch (Facebook), further contributes to DL promises on the democratization
    of computational analytics. However, increased technical and specialized background
    is required to develop DL algorithms, and the variability of implementation details
    hinders their reproducibility. Towards lowering the barrier and making the mechanism
    of DL development, training, and inference more stable, reproducible, and scalable,
    without requiring an extensive technical background, this manuscript proposes
    the Generally Nuanced Deep Learning Framework (GaNDLF). With built-in support
    for k-fold cross-validation, data augmentation, multiple modalities and output
    classes, and multi-GPU training, as well as the ability to work with both radiographic
    and histologic imaging, GaNDLF aims to provide an end-to-end solution for all
    DL-related tasks, to tackle problems in medical imaging and provide a robust application
    framework for deployment in clinical workflows.


    Keywords: Deep Learning, Framework, Segmentation, Regression, Classification,
    Cross-validation, Data

    augmentation, Deployment, Clinical, Workflows'
  link: ''
  poster_link: https://assets.pytorch.org/pted2021/posters/D8.png
  section: D8
  thumbnail_link: https://assets.pytorch.org/pted2021/posters/thumb-D8.png
  title: " GaNDLF \u2013 A Generally Nuanced Deep Learning Framework for Clinical\
    \ Imaging Workflows"
